[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Teste de eficiência de controle da traça-do-tomateiro (Phthorimaea absoluta)",
    "section": "",
    "text": "Teste de eficiência de controle da traça-do-tomateiro (Phthorimaea absoluta)\nEste site foi desenvolvido para apresentar as informações relacionadas à análise de dados sobre a eficiência de diferentes inseticidas no controle da traça-do-tomateiro (Phthorimaea absoluta). O conteúdo faz parte do trabalho final da disciplina FIP 606 – Análise e Visualização de Dados em Fitopatologia, ministrada pelo professor Emerson Del Ponte.\nA análise realizada fornece um panorama dos efeitos de diversos inseticidas na supressão da praga, permitindo comparar sua eficácia com base em dados experimentais."
  },
  {
    "objectID": "aplicativo.html#principais-funcionalidades",
    "href": "aplicativo.html#principais-funcionalidades",
    "title": "Aplicativo de análise de teste de eficiência de inseticidas no controle de pragas - MIPanálise",
    "section": "Principais Funcionalidades",
    "text": "Principais Funcionalidades\nNosso aplicativo foi projetado para ser uma plataforma completa para suas necessidades de análise de dados de eficiência de inseticidas no controle de pragas incluindo:\n\nImportação de Dados Flexível: Carregue seus conjuntos de dados facilmente a partir de arquivos CSV ou Excel, com opções para configurar cabeçalhos e separadores.\nPré-visualização de Dados: Visualize rapidamente as primeiras linhas do seu conjunto de dados importado para garantir que tudo esteja correto antes de prosseguir.\nSeleção Dinâmica de Variáveis: Escolha as variáveis de tratamento, resposta e repetição diretamente das colunas do seu arquivo, adaptando-se às suas necessidades de análise.\nAnálises Estatísticas Essenciais: Realize testes estatísticos fundamentais como:\n\nANOVA (Análise de Variância): Para comparar médias entre três ou mais grupos.\nGLM (Modelos Lineares Generalizados): Para analisar dados com diferentes distribuições (Gaussian, Binomial, Poisson) e funções de link.\nGLMM (Modelos Lineares Generalizados Mistos): Ideal para dados com estruturas de repetição ou agrupamento.\nProbit: Para análises de dose-resposta, comum em estudos de toxicologia e eficácia.\nCorreção de Abbott: Calcule a eficiência corrigida de tratamentos, ajustando para a mortalidade natural.\n\nGráficos Interativos: Gere visualizações dinâmicas dos seus resultados, como boxplots e curvas de dose-resposta, com a interatividade do Plotly.\nRelatórios Completos: Baixe seus dados, gráficos e os resultados detalhados das análises em formatos convenientes (CSV, PNG, PDF).\nGerenciamento de Sessões: Salve o estado atual do seu trabalho para retomar mais tarde, garantindo que você nunca perca seu progresso.\nBulas de Produtos e Glossário: Acesse um recurso útil de bulas de produtos (se aplicável ao contexto da sua disciplina) e um glossário de termos técnicos para referência rápida.\nAgenda de Experimentos: Mantenha um registro organizado dos seus experimentos e sessões salvas, com filtros por data e nome do experimento."
  },
  {
    "objectID": "aplicativo.html#organização-do-aplicativo",
    "href": "aplicativo.html#organização-do-aplicativo",
    "title": "Aplicativo de análise de teste de eficiência de inseticidas no controle de pragas - MIPanálise",
    "section": "Organização do Aplicativo",
    "text": "Organização do Aplicativo\nO aplicativo é estruturado em abas intuitivas para guiar você através do processo de análise:\n\nInício: Esta aba (onde você está agora!) oferece uma visão geral do aplicativo e suas principais funcionalidades.\nImportar Dados: O ponto de partida para carregar seus arquivos de dados.\nConfiguração: Defina suas variáveis de análise e ajuste as opções específicas dos modelos estatísticos.\nAnálises: Escolha o tipo de análise estatística que deseja executar e visualize os resultados.\nGráficos: Explore seus dados visualmente através de gráficos interativos.\nDownload: Exporte suas tabelas, gráficos e relatórios completos.\nProdutos e Bulas: (Se aplicável) Consulte informações e bulas de produtos.\nGlossário: Encontre definições claras para termos técnicos.\nSalvar/Carregar Sessão: Gerencie suas sessões de trabalho para salvar e carregar o progresso.\nRecomendações: Obtenha dicas e boas práticas para suas análises.\nAgenda: Acompanhe e filtre seus experimentos e sessões salvas.\nAjuda: Um guia detalhado sobre como usar cada funcionalidade do aplicativo."
  },
  {
    "objectID": "aplicativo.html#recomendações-para-o-uso-eficiente",
    "href": "aplicativo.html#recomendações-para-o-uso-eficiente",
    "title": "Aplicativo de análise de teste de eficiência de inseticidas no controle de pragas - MIPanálise",
    "section": "Recomendações para o Uso Eficiente",
    "text": "Recomendações para o Uso Eficiente\nPara aproveitar ao máximo o aplicativo e garantir a precisão de suas análises, considere as seguintes recomendações:\n\nPrepare seus Dados: Antes de importar, certifique-se de que suas planilhas estejam limpas, organizadas e que as colunas de interesse estejam formatadas corretamente (ex: números para variáveis quantitativas, texto para fatores).\nEntenda as Variáveis: Tenha clareza sobre qual coluna representa seu tratamento, qual é a variável de resposta e se há repetições em seu experimento.\nExplore as Configurações: As opções de Família GLM e Função de Link GLM, bem como a Variável de Total para Probit, são cruciais para o ajuste correto do modelo. Consulte o glossário e os materiais da disciplina para fazer as escolhas adequadas.\nSalve Regularmente: Utilize a funcionalidade de “Salvar Sessão” com frequência para evitar a perda de trabalho, especialmente ao realizar análises mais complexas ou demoradas.\nConsulte o Glossário e a Ajuda: Em caso de dúvidas sobre termos estatísticos ou funcionalidades do aplicativo, o glossário e a aba de ajuda são recursos valiosos.\nUse os Dados de Exemplo: Se você é novo no aplicativo, comece carregando os “Dados de Exemplo” para se familiarizar com a interface e testar as funcionalidades sem impactar seus próprios dados."
  },
  {
    "objectID": "aplicativo.html#suporte-e-contato",
    "href": "aplicativo.html#suporte-e-contato",
    "title": "Aplicativo de análise de teste de eficiência de inseticidas no controle de pragas - MIPanálise",
    "section": "Suporte e Contato",
    "text": "Suporte e Contato\nPara dúvidas, sugestões ou suporte técnico, entre em contato com a equipe de desenvolvimento. Sua opinião é muito importante para nós!\nEmail: damaris.freitas@ufv.br e leticia.ana@ufv.br\nVersão do Aplicativo: 1.0.0"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Obtenção dos dados",
    "section": "",
    "text": "Os experimentos foram conduzidos no Laboratório de Manejo Integrado de Pragas – MIP-UFV, durante os anos de 2022 a 2023."
  },
  {
    "objectID": "about.html#condições-experimentais",
    "href": "about.html#condições-experimentais",
    "title": "Obtenção dos dados",
    "section": "",
    "text": "Os experimentos foram conduzidos no Laboratório de Manejo Integrado de Pragas – MIP-UFV, durante os anos de 2022 a 2023."
  },
  {
    "objectID": "about.html#insetos",
    "href": "about.html#insetos",
    "title": "Obtenção dos dados",
    "section": "Insetos",
    "text": "Insetos\nAs lagartas da traça do tomateiro foram obtidas de criações mantidas a 20 anos no Laboratório MIP-UFV. Essa criação é constituída por indivíduos da população de Viçosa, que é um padrão de suscetibilidade a inseticidas."
  },
  {
    "objectID": "about.html#determinação-da-eficiência-dos-inseticidas-a-traça-do-tomateiro",
    "href": "about.html#determinação-da-eficiência-dos-inseticidas-a-traça-do-tomateiro",
    "title": "Obtenção dos dados",
    "section": "Determinação da eficiência dos inseticidas a traça do tomateiro",
    "text": "Determinação da eficiência dos inseticidas a traça do tomateiro\nO delineamento experimental foi inteiramente casualizado, com 14 tratamentos além do controle, com seis repetições. No controle foi empregado somente água. A escolha dos inseticidas foi realizada de forma a abranger os principais produtos utilizados pelos produtores no controle desta praga no Brasil. Os inseticidas foram empregados na dosagem comercial utilizada para o controle da traça do tomateiro. Os inseticidas utilizados e suas dosagens foram: TABELA (colocar na tabela se é regulador ou outra coisa).\nPara instalação deste bioensaio, folhas de tomate foram imersas em caldas inseticidas por cinco segundos. As folhas foram colocadas para secar, e após, acondicionadas em potes plásticos de 50 mL, com tampa furada e vedada com organza. As folhas foram inseridas no pote com o auxílio de uma pinça, e as lagartas foram transferidas com pincel. Cada folha recebeu 10 lagartas de traça-do-tomateiro. Os potes foram levados para BOD a temperatura de 25 ± 0,5 °C e umidade relativa de 75 ± 5%.\nAs avaliações do número de insetos mortos por unidade experimental foram realizadas após 24 horas, se estender até 168 horas, a depender do inseticida (regulador de crescimento). Foram considerados como mortos os insetos que não eram capazes de se deslocar o dobro do seu comprimento. (colocar vídeo mergulhando a folha)."
  },
  {
    "objectID": "analises.html",
    "href": "analises.html",
    "title": "Análise dos dados do experimento de eficiência de inseticidas no controle de lagartas da traça-do-tomateiro",
    "section": "",
    "text": "Por meio da análise dos dados, objetivou-se determinar a eficiência de inseticidas no controle de lagartas de Phthorimaea absoluta.\n\n\n\nHipótese nula (H0): Não há diferença significativa entre os tratamentos. A média da eficiência dos tratamentos no controle é igual para todos os inseticidas.\nHipótese alternativa (Ha): Pelo menos um dos inseticidas apresenta um desempenho significativamente melhor do que o controle, em comparação com os demais."
  },
  {
    "objectID": "analises.html#hipóteses-testadas",
    "href": "analises.html#hipóteses-testadas",
    "title": "Análise dos dados do experimento de eficiência de inseticidas no controle de lagartas da traça-do-tomateiro",
    "section": "",
    "text": "Hipótese nula (H0): Não há diferença significativa entre os tratamentos. A média da eficiência dos tratamentos no controle é igual para todos os inseticidas.\nHipótese alternativa (Ha): Pelo menos um dos inseticidas apresenta um desempenho significativamente melhor do que o controle, em comparação com os demais."
  },
  {
    "objectID": "analises.html#pré-análise-dos-dados",
    "href": "analises.html#pré-análise-dos-dados",
    "title": "Análise dos dados do experimento de eficiência de inseticidas no controle de lagartas da traça-do-tomateiro",
    "section": "Pré-análise dos dados",
    "text": "Pré-análise dos dados\nPacotes: os seguintes pacotes R foram utilizados para as análises.\n\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(forcats)\nlibrary(stringr)\nlibrary(plotly)\nlibrary(readr)\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)\nlibrary(DHARMa)\nlibrary(car)\nlibrary(glmmTMB)\nlibrary(lme4)\nlibrary(performance)\nlibrary(MASS)\nlibrary(dunn.test)\n\nCarregamento dos dados: como o dataframe contendo os dados de eficiência dos inseticidas estava localizado em uma planilha Excel no desktop, para o carregamento dos dados, foi necessário utilizar a função read_excel do pacote readxl. O dataframe foi atribuído ao objeto denominado dados.\n\ndados &lt;- read_excel(\"teste_lagarta_traça.xlsx\")\n\ndados\n\n# A tibble: 96 × 6\n   tratamento repetição tempo vivos mortos total\n   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 abamex             1    48     0     10    10\n 2 abamex             2    48     0     10    10\n 3 abamex             3    48     0     10    10\n 4 abamex             4    48     0     10    10\n 5 abamex             5    48     0     10    10\n 6 abamex             6    48     0     10    10\n 7 actara             1    48     6      4    10\n 8 actara             2    48     4      6    10\n 9 actara             3    48     6      4    10\n10 actara             4    48     5      5    10\n# ℹ 86 more rows"
  },
  {
    "objectID": "analises.html#análise-visual-dos-dados",
    "href": "analises.html#análise-visual-dos-dados",
    "title": "Análise dos dados do experimento de eficiência de inseticidas no controle de lagartas da traça-do-tomateiro",
    "section": "Análise visual dos dados",
    "text": "Análise visual dos dados\nUsando o pacote ggplot2, foi explorado visualmente, por meio de diferentes gráficos, os dados de eficiência dos inseticidas.\nGráfico de barras: primeiramente, foi visualizada a proporção de mortalidade de insetos em cada tratamento. A proporção de insetos mortos foi calculada pela fórmula:\n\\(PM = TM / (TV + TM)\\)\nPM = proporção de mortos\nTM = total de insetos mortos no tratamento\nTV = total de insetos vivos no tratamento\n\nproporcao_mortos &lt;- dados |&gt;\n  group_by(tratamento) |&gt;\n  summarise(\n    TM = sum(mortos, na.rm = TRUE),\n    TV = sum(vivos, na.rm = TRUE)\n  ) |&gt;\n  mutate(\n    tratamento = str_to_title(tratamento),\n    PM = TM / (TM + TV)\n  ) |&gt;\n  ungroup() |&gt;\n  arrange(PM) |&gt;\n  mutate(tratamento = factor(tratamento, levels = tratamento)) \n     \nprint(proporcao_mortos)\n\n# A tibble: 16 × 4\n   tratamento    TM    TV     PM\n   &lt;fct&gt;      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Controle       1    59 0.0167\n 2 Actara        30    30 0.5   \n 3 Benevia       43    17 0.717 \n 4 Premio        44    16 0.733 \n 5 Nomolt        23     7 0.767 \n 6 Hayate        51     9 0.85  \n 7 Tracer        53     7 0.883 \n 8 Avatar        56     4 0.933 \n 9 Belt          57     3 0.95  \n10 Vertimec      58     2 0.967 \n11 Talstar       59     1 0.983 \n12 Abamex        60     0 1     \n13 Cartap        60     0 1     \n14 Delegate      60     0 1     \n15 Joiner        60     0 1     \n16 Pirate        60     0 1     \n\ngrafico_proporcao &lt;- ggplot(proporcao_mortos, aes(x = tratamento, y = PM)) +\n  geom_col(fill = \"darkgreen\") +\n  labs(\n    title = \"Proporção de insetos mortos por tratamento\",\n    x = \"Tratamentos\",\n    y = \"Proporção de mortos\"\n  ) +\n  ylim(0, 1) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(size = 18, face = \"bold\", hjust = 0.5),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid.major.x = element_blank(),  \n    panel.grid.minor.x = element_blank())\n\ngrafico_interativo &lt;- plotly::ggplotly(grafico_proporcao) |&gt;\n  plotly::config(displayModeBar = FALSE)\n\ngrafico_interativo\n\n\n\n\n\nAdição de facetas: a visualização de cada tratamento individualmente foi possibilitada pela adição de facetas, permitindo analisar o comportamento de cada repetição (número de insetos mortos). Isso foi feito com a função facet_wrap.\n\ndados |&gt;\n  ggplot(aes(repetição, mortos))+\n  geom_col(fill = \"darkgreen\")+\n  labs(x = \"Repetições\",\n       y = \"Número de insetos mortos\")+\n  theme_bw()+\n  theme(panel.grid.minor = element_blank())+\n  scale_y_continuous(limits = c(0, 10), n.breaks = 3)+\n  facet_wrap(~ tratamento, labeller = labeller(tratamento = tools::toTitleCase))"
  },
  {
    "objectID": "analises.html#mortalidade",
    "href": "analises.html#mortalidade",
    "title": "Análise dos dados do experimento de eficiência de inseticidas no controle de lagartas da traça-do-tomateiro",
    "section": "Mortalidade",
    "text": "Mortalidade\nA mortalidade é descrita como:\n\\(MT = M / T\\)\nMT = mortalidade\nM = mortos\nT = total\n\ndados &lt;- dados |&gt;\n  mutate(\n    mortalidade = mortos / total)\n\nmedia_mortalidade &lt;- dados |&gt;\n  group_by(tratamento) |&gt;\n  summarise(\n    mortalidade_media = mean(mortalidade, na.rm = TRUE),\n    .groups = \"drop\")\n\nmortalidade_controle &lt;- media_mortalidade |&gt;\n  filter(grepl(\"controle\", tolower(tratamento))) |&gt;\n  pull(mortalidade_media)\n\nprint(mortalidade_controle)\n\n[1] 0.01666667\n\nprint(media_mortalidade)\n\n# A tibble: 16 × 2\n   tratamento mortalidade_media\n   &lt;chr&gt;                  &lt;dbl&gt;\n 1 abamex                1     \n 2 actara                0.5   \n 3 avatar                0.933 \n 4 belt                  0.95  \n 5 benevia               0.717 \n 6 cartap                1     \n 7 controle              0.0167\n 8 delegate              1     \n 9 hayate                0.85  \n10 joiner                1     \n11 nomolt                0.767 \n12 pirate                1     \n13 premio                0.733 \n14 talstar               0.983 \n15 tracer                0.883 \n16 vertimec              0.967"
  },
  {
    "objectID": "analises.html#análise-das-pressuposições-da-anova",
    "href": "analises.html#análise-das-pressuposições-da-anova",
    "title": "Análise dos dados do experimento de eficiência de inseticidas no controle de lagartas da traça-do-tomateiro",
    "section": "Análise das pressuposições da ANOVA",
    "text": "Análise das pressuposições da ANOVA\nPara que a ANOVA seja realizada é necessário que ela se enquandre nos seguintes pressupostos:\n\nNormalidade dos resíduos\nHomogeneidade de variâncias (homocedasticidade)\nAditividade do modelo\n\n\nmodelo_anova &lt;- aov(mortalidade ~ tratamento, data = dados)\n\nsummary(modelo_anova)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)    \ntratamento  15  6.070  0.4046   65.18 &lt;2e-16 ***\nResiduals   80  0.497  0.0062                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHistograma dos resíduos: foi criado o histograma dos resíduos da ANOVA, criado com a função hist a partir do objeto modelo_anova, serve para visualizar a distribuição desses resíduos. Isso permite verificar se eles são aproximadamente normais, uma suposição fundamental para a validade dos resultados da ANOVA.\n\nhist(residuals(modelo_anova))\n\n\n\n\n\n\n\n\n\nplot(simulateResiduals(modelo_anova))\n\n\n\n\n\n\n\n\nNormalidade dos resíduos: foi verificada pelo Shapiro teste, executado a partir da função shapiro.test a partir do objeto modelo_anova.\n\nshapiro.test(residuals(modelo_anova))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo_anova)\nW = 0.90715, p-value = 4.649e-06\n\n\nComo p-valor &lt; 0.05, os resíduos não possuem normalidade.\nHomogeneidade das variâncias: foi testada pelo teste de Levene, por meio da função leveneTest aplicada a mortalidade por tratamento.\n\ncar::leveneTest(mortalidade ~ tratamento, data = dados)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value    Pr(&gt;F)    \ngroup 15   3.598 9.517e-05 ***\n      80                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nComo o p-valor &lt; 0.05, as variâncias são heterogêneas.\nAssim, observamos que os dados não atendem as pressuposições da ANOVA. Assim, se torna necessária a transformação dos dados ou a utilização de outros testes e modelos para a análise de dados. Com isso, apresentamos as duas formas de análise dos dados."
  },
  {
    "objectID": "analises.html#transformação-dos-dados",
    "href": "analises.html#transformação-dos-dados",
    "title": "Análise dos dados do experimento de eficiência de inseticidas no controle de lagartas da traça-do-tomateiro",
    "section": "Transformação dos dados",
    "text": "Transformação dos dados\nOs dados foram transformados pela função asin(sqrt(x)) (arcseno da raiz quadrada). É uma transformação usada para estabilizar a variância de proporções.\n\ndados &lt;- dados %&gt;%\n  mutate(\n    anscombe = asin(sqrt((mortos + 3/8) / (total + 3/4)))\n  )\n\nprint(dados)\n\n# A tibble: 96 × 8\n   tratamento repetição tempo vivos mortos total mortalidade anscombe\n   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;\n 1 abamex             1    48     0     10    10         1      1.38 \n 2 abamex             2    48     0     10    10         1      1.38 \n 3 abamex             3    48     0     10    10         1      1.38 \n 4 abamex             4    48     0     10    10         1      1.38 \n 5 abamex             5    48     0     10    10         1      1.38 \n 6 abamex             6    48     0     10    10         1      1.38 \n 7 actara             1    48     6      4    10         0.4    0.692\n 8 actara             2    48     4      6    10         0.6    0.879\n 9 actara             3    48     6      4    10         0.4    0.692\n10 actara             4    48     5      5    10         0.5    0.785\n# ℹ 86 more rows\n\n\nAplicando a ANOVA novamente\n\nmodelo_anova2 &lt;- aov(anscombe ~ tratamento, data = dados)\n\nHistograma dos resíduos\n\nhist(residuals(modelo_anova2))\n\n\n\n\n\n\n\n\nNormalidade dos resíduos\n\nshapiro.test(residuals(modelo_anova2))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo_anova2)\nW = 0.93441, p-value = 0.0001243\n\n\nComo o p-valor &lt; 0.05, os resíduos não são normais.\nHomogeneidade das variâncias\n\ncar::leveneTest(anscombe ~ tratamento, data = dados)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value    Pr(&gt;F)    \ngroup 15  3.0498 0.0006496 ***\n      80                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nComo o p-valor &lt; 0.05, as variâncias são heterogêneas.\nAssim, observamos que a transformação dos dados não foi suficiente para que eles atendessem as pressuposições da ANOVA."
  },
  {
    "objectID": "analises.html#teste-de-kruskal-wallis",
    "href": "analises.html#teste-de-kruskal-wallis",
    "title": "Análise dos dados do experimento de eficiência de inseticidas no controle de lagartas da traça-do-tomateiro",
    "section": "Teste de Kruskal-Wallis",
    "text": "Teste de Kruskal-Wallis\nO teste de Kruskal-Wallis é um teste não-paramétrico que verifica se há diferenças significativas entre os tratamentos analisados. Assim, ele foi aplicado aos dados de mortalidade.\n\nkruskal.test(mortalidade ~ tratamento, data = dados)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  mortalidade by tratamento\nKruskal-Wallis chi-squared = 77.032, df = 15, p-value = 2.427e-10\n\n\nComo p-valor &lt; 0.05, há diferenças significativas na mortalidade entre os tratamentos.\n\nComparações múltiplas\nPara realizar as comparações dos tratamentos foi realizado o teste de Dunn.\n\nteste_dunn &lt;- dunn.test(dados$mortalidade, dados$tratamento, method = \"holm\")\n\n  Kruskal-Wallis rank sum test\n\ndata: x and group\nKruskal-Wallis chi-squared = 77.0316, df = 15, p-value = 0\n\n                           Comparison of x by group                            \n                                    (Holm)                                     \nCol Mean-|\nRow Mean |     abamex     actara     avatar       belt    benevia     cartap\n---------+------------------------------------------------------------------\n  actara |   4.145820\n         |    0.0019*\n         |\n  avatar |   1.463230  -2.682589\n         |     1.0000     0.3141\n         |\n    belt |   1.097423  -3.048397  -0.365807\n         |     1.0000     0.1081     1.0000\n         |\n benevia |   3.297811  -0.848008   1.834581   2.200388\n         |     0.0512     1.0000     1.0000     1.0000\n         |\n  cartap |   0.000000  -4.145820  -1.463230  -1.097423  -3.297811\n         |     1.0000    0.0019*     1.0000     1.0000     0.0507\n         |\ncontrole |   4.622479   0.476658   3.159248   3.525056   1.324667   4.622479\n         |    0.0002*     1.0000     0.0751    0.0227*     1.0000    0.0002*\n         |\ndelegate |   0.000000  -4.145820  -1.463230  -1.097423  -3.297811   0.000000\n         |     1.0000    0.0019*     1.0000     1.0000     0.0502     1.0000\n         |\n  hayate |   2.023027  -2.122793   0.559796   0.925604  -1.274784   2.023027\n         |     1.0000     1.0000     1.0000     1.0000     1.0000     1.0000\n         |\n  joiner |   0.000000  -4.145820  -1.463230  -1.097423  -3.297811   0.000000\n         |     1.0000    0.0019*     1.0000     1.0000     0.0497     1.0000\n         |\n  nomolt |   2.810068  -1.335752   1.346837   1.712645  -0.487743   2.810068\n         |     0.2254     1.0000     1.0000     1.0000     1.0000     0.2229\n         |\n  pirate |   0.000000  -4.145820  -1.463230  -1.097423  -3.297811   0.000000\n         |     1.0000    0.0019*     1.0000     1.0000     0.0492     1.0000\n         |\n  premio |   3.181418  -0.964402   1.718187   2.083995  -0.116393   3.181418\n         |     0.0733     1.0000     1.0000     1.0000     1.0000     0.0725\n         |\n talstar |   0.365807  -3.780012  -1.097423  -0.731615  -2.932004   0.365807\n         |     1.0000    0.0085*     1.0000     1.0000     0.1566     1.0000\n         |\n  tracer |   2.333409  -1.812410   0.870178   1.235986  -0.964402   2.333409\n         |     0.7949     1.0000     1.0000     1.0000     1.0000     0.7851\n         |\nvertimec |   0.731615  -3.414205  -0.731615  -0.365807  -2.566196   0.731615\n         |     1.0000     0.0339     1.0000     1.0000     0.4318     1.0000\nCol Mean-|\nRow Mean |   controle   delegate     hayate     joiner     nomolt     pirate\n---------+------------------------------------------------------------------\ndelegate |  -4.622479\n         |    0.0002*\n         |\n  hayate |  -2.599451   2.023027\n         |     0.3968     1.0000\n         |\n  joiner |  -4.622479   0.000000  -2.023027\n         |    0.0002*     1.0000     1.0000\n         |\n  nomolt |  -1.812410   2.810068   0.787040   2.810068\n         |     1.0000     0.2204     1.0000     0.2179\n         |\n  pirate |  -4.622479   0.000000  -2.023027   0.000000  -2.810068\n         |    0.0002*     1.0000     1.0000     0.5000     0.2155\n         |\n  premio |  -1.441060   3.181418   1.158391   3.181418   0.371350   3.181418\n         |     1.0000     0.0718     1.0000     0.0711     1.0000     0.0703\n         |\n talstar |  -4.256671   0.365807  -1.657219   0.365807  -2.444260   0.365807\n         |    0.0012*     1.0000     1.0000     1.0000     0.5951     1.0000\n         |\n  tracer |  -2.289069   2.333409   0.310382   2.333409  -0.476658   2.333409\n         |     0.8389     0.7753     1.0000     0.7654     1.0000     0.7556\n         |\nvertimec |  -3.890863   0.731615  -1.291412   0.731615  -2.078452   0.731615\n         |    0.0054*     1.0000     1.0000     1.0000     1.0000     1.0000\nCol Mean-|\nRow Mean |     premio    talstar     tracer\n---------+---------------------------------\n talstar |  -2.815610\n         |     0.2239\n         |\n  tracer |  -0.848008   1.967602\n         |     1.0000     1.0000\n         |\nvertimec |  -2.449803   0.365807  -1.601794\n         |     0.5932     1.0000     1.0000\n\nalpha = 0.05\nReject Ho if p &lt;= alpha/2\n\n\n\ncomparacoes &lt;- teste_dunn$comparisons\npvals &lt;- teste_dunn$P.adjusted\ngrupos &lt;- unique(as.character(dados$tratamento))\nmatriz_p &lt;- matrix(1, nrow = length(grupos), ncol = length(grupos),\n                   dimnames = list(grupos, grupos))\n\nfor (i in seq_along(comparacoes)) {\n  par &lt;- unlist(strsplit(comparacoes[i], \" - \"))\n  matriz_p[par[1], par[2]] &lt;- pvals[i]\n  matriz_p[par[2], par[1]] &lt;- pvals[i]\n}\n\nletras &lt;- multcompLetters(matriz_p)$Letters\nletras_df &lt;- data.frame(tratamento = names(letras), letra = letras)\n\nsummary_ic &lt;- dados %&gt;%\n  group_by(tratamento) %&gt;%\n  summarise(\n    media = mean(mortalidade, na.rm = TRUE),\n    n = n(),\n    sd = sd(mortalidade, na.rm = TRUE),\n    se = sd / sqrt(n),\n    ic = qt(0.975, df = n - 1) * se\n  )\n\nplot_df &lt;- summary_ic %&gt;%\n  left_join(letras_df, by = \"tratamento\") %&gt;%\n  mutate(tratamento = str_to_title(tratamento))  \n\nggplot(plot_df, aes(x = tratamento, y = media)) +\n  geom_errorbar(aes(ymin = media - ic, ymax = media + ic), width = 0.2) +\n  geom_point(size = 3) +\n  geom_text(aes(label = letra, y = media + ic + 0.03), size = 5) +\n  labs(\n    title = \"Mortalidade por tratamento (Teste de Dunn)\",\n    x = \"Tratamento\",\n    y = \"Mortalidade\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )"
  },
  {
    "objectID": "analises.html#modelos-alternativos",
    "href": "analises.html#modelos-alternativos",
    "title": "Análise dos dados do experimento de eficiência de inseticidas no controle de lagartas da traça-do-tomateiro",
    "section": "Modelos alternativos",
    "text": "Modelos alternativos\nUma forma de analisar os dados sem transformação é a utilização de modelos que não exigem características semelhantes a da ANOVA. Dentre eles pode ser utilizado o GLM e GLMM.\n\nAjuste dos dados\nComo possuimos dados com valores de 0 ou 100% (ou seja, tudo morto ou tudo vivo), o modelo encontra problemas. Assim, os dados foram ajustado adicionando 0.5 ao número de mortos e vivos. A função cbind foi utilizada, pois estamos tratando de contagem de eventos (morto x vivo).\n\ndados$tratamento &lt;- as.factor(dados$tratamento)\n\ndados_ajustados &lt;- dados |&gt;\n  dplyr::filter(mortos + vivos &gt; 0) |&gt;  \n  dplyr::mutate(\n    mortos_ajustados = mortos + 0.5,\n    vivos_ajustados = vivos + 0.5,\n    resposta_binomial = cbind(mortos_ajustados, vivos_ajustados))\n\n\n\nGLM - Modelo linear generalizado\nInicialmente, foi testado o modelo com distribuição binomial. Esse modelo é indicado quando os dados são proporcionais (insetos mortos / vivos). Com isso, é possível verificar se há diferença significativa entre os inseticidas testados quanto à mortalidade dos insetos. O argumento family = binomial foi utilizada por ter apenas dois resultados possíveis (sucesso ou fracasso). O link logit foi utilizado por se tratar de dados de proporção.\n\nmodelo_glm &lt;- glm(resposta_binomial ~ tratamento,\n                                 family = binomial(link = \"logit\"),\n                                 data = dados_ajustados)\n\nsummary(modelo_glm)\n\n\nCall:\nglm(formula = resposta_binomial ~ tratamento, family = binomial(link = \"logit\"), \n    data = dados_ajustados)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)         3.045e+00  5.909e-01   5.152 2.58e-07 ***\ntratamentoactara   -3.045e+00  6.402e-01  -4.756 1.98e-06 ***\ntratamentoavatar   -9.129e-01  7.134e-01  -1.280 0.200698    \ntratamentobelt     -7.419e-01  7.297e-01  -1.017 0.309291    \ntratamentobenevia  -2.212e+00  6.488e-01  -3.409 0.000652 ***\ntratamentocartap   -8.319e-15  8.357e-01   0.000 1.000000    \ntratamentocontrole -5.785e+00  7.844e-01  -7.375 1.64e-13 ***\ntratamentodelegate -5.482e-15  8.357e-01   0.000 1.000000    \ntratamentohayate   -1.540e+00  6.716e-01  -2.294 0.021808 *  \ntratamentojoiner   -6.571e-15  8.357e-01   0.000 1.000000    \ntratamentonomolt   -2.089e+00  6.983e-01  -2.991 0.002776 ** \ntratamentopirate   -6.974e-15  8.357e-01   0.000 1.000000    \ntratamentopremio   -2.139e+00  6.505e-01  -3.288 0.001008 ** \ntratamentotalstar  -3.037e-01  7.844e-01  -0.387 0.698651    \ntratamentotracer   -1.322e+00  6.834e-01  -1.934 0.053106 .  \ntratamentovertimec -5.431e-01  7.521e-01  -0.722 0.470209    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 331.240  on 95  degrees of freedom\nResidual deviance:  26.177  on 80  degrees of freedom\nAIC: 274.57\n\nNumber of Fisher Scoring iterations: 4\n\nanova_glm &lt;- anova(modelo_glm, data = dados_ajustados)\nprint(anova_glm)\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: resposta_binomial\n\nTerms added sequentially (first to last)\n\n           Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nNULL                          95     331.24              \ntratamento 15   305.06        80      26.18 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(modelo_glm))\n\n\n\n\n\n\n\nqqnorm(residuals(modelo_glm))\nqqline(residuals(modelo_glm))\n\n\n\n\n\n\n\n\n\nres_dev_binomial &lt;- sum(residuals(modelo_glm, type = \"deviance\")^2)\ndf_binomial &lt;- df.residual(modelo_glm)\ndispersion_param_binomial &lt;- res_dev_binomial / df_binomial\nprint(dispersion_param_binomial)\n\n[1] 0.3272128\n\n\nA análise do Modelo Linear Generalizado (GLM) com família binomial revelou um parâmetro de dispersão residual de 0.3272128. Este valor, que é menor que 1, indicando a presença de subdispersão nos dados. Embora o teste de dispersão do DHARMa não tenha sido estatisticamente significativo (p = 0.184), a magnitude do parâmetro estimado (0.327) sugere que a variabilidade observada é consideravelmente menor do que a esperada sob a distribuição binomial padrão. Assim, a family foi ajustada para quasibinomial.\nDistribuição quasibinomial: o modelo GLM foi ajustado usando o argumento family = quasibinomial. Ele permite que o parâmetro de dispersão dos dados seja estimado, corrigindo os erros padrão e os testes de significância.\n\nmodelo_glm_qb &lt;- glm(resposta_binomial ~ tratamento,\n                                 family = quasibinomial(link = \"logit\"),\n                                 data = dados_ajustados)\n\nsummary(modelo_glm_qb)\n\n\nCall:\nglm(formula = resposta_binomial ~ tratamento, family = quasibinomial(link = \"logit\"), \n    data = dados_ajustados)\n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         3.045e+00  3.334e-01   9.132 4.84e-14 ***\ntratamentoactara   -3.045e+00  3.612e-01  -8.430 1.16e-12 ***\ntratamentoavatar   -9.129e-01  4.025e-01  -2.268 0.026029 *  \ntratamentobelt     -7.419e-01  4.117e-01  -1.802 0.075304 .  \ntratamentobenevia  -2.212e+00  3.660e-01  -6.042 4.57e-08 ***\ntratamentocartap   -8.319e-15  4.715e-01   0.000 1.000000    \ntratamentocontrole -5.785e+00  4.426e-01 -13.072  &lt; 2e-16 ***\ntratamentodelegate -5.482e-15  4.715e-01   0.000 1.000000    \ntratamentohayate   -1.540e+00  3.789e-01  -4.065 0.000111 ***\ntratamentojoiner   -6.571e-15  4.715e-01   0.000 1.000000    \ntratamentonomolt   -2.089e+00  3.940e-01  -5.302 9.91e-07 ***\ntratamentopirate   -6.974e-15  4.715e-01   0.000 1.000000    \ntratamentopremio   -2.139e+00  3.670e-01  -5.828 1.13e-07 ***\ntratamentotalstar  -3.037e-01  4.426e-01  -0.686 0.494580    \ntratamentotracer   -1.322e+00  3.856e-01  -3.428 0.000963 ***\ntratamentovertimec -5.431e-01  4.243e-01  -1.280 0.204264    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasibinomial family taken to be 0.3183159)\n\n    Null deviance: 331.240  on 95  degrees of freedom\nResidual deviance:  26.177  on 80  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 4\n\nm &lt;- emmeans(modelo_glm_qb, ~ tratamento, type = \"response\")\nprint(m)\n\n tratamento   prob     SE  df asymp.LCL asymp.UCL\n abamex     0.9545 0.0145 Inf    0.9161     0.976\n actara     0.5000 0.0347 Inf    0.4324     0.568\n avatar     0.8939 0.0214 Inf    0.8442     0.929\n belt       0.9091 0.0200 Inf    0.8617     0.941\n benevia    0.6970 0.0319 Inf    0.6311     0.756\n cartap     0.9545 0.0145 Inf    0.9161     0.976\n controle   0.0606 0.0166 Inf    0.0352     0.102\n delegate   0.9545 0.0145 Inf    0.9161     0.976\n hayate     0.8182 0.0268 Inf    0.7597     0.865\n joiner     0.9545 0.0145 Inf    0.9161     0.976\n nomolt     0.7222 0.0421 Inf    0.6328     0.797\n pirate     0.9545 0.0145 Inf    0.9161     0.976\n premio     0.7121 0.0314 Inf    0.6468     0.770\n talstar    0.9394 0.0166 Inf    0.8976     0.965\n tracer     0.8485 0.0249 Inf    0.7930     0.891\n vertimec   0.9242 0.0184 Inf    0.8794     0.953\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the logit scale \n\ncld_results &lt;- cld(m, adjust = \"Tukey\", Letters = LETTERS)\nprint(cld_results)\n\n tratamento   prob     SE  df asymp.LCL asymp.UCL .group  \n controle   0.0606 0.0166 Inf    0.0266     0.132  A      \n actara     0.5000 0.0347 Inf    0.3990     0.601   B     \n benevia    0.6970 0.0319 Inf    0.5957     0.782    C    \n premio     0.7121 0.0314 Inf    0.6115     0.795    CD   \n nomolt     0.7222 0.0421 Inf    0.5834     0.828    CD   \n hayate     0.8182 0.0268 Inf    0.7258     0.884    CDE  \n tracer     0.8485 0.0249 Inf    0.7598     0.908     DEF \n avatar     0.8939 0.0214 Inf    0.8126     0.942      EFG\n belt       0.9091 0.0200 Inf    0.8307     0.953      EFG\n vertimec   0.9242 0.0184 Inf    0.8491     0.964      EFG\n talstar    0.9394 0.0166 Inf    0.8679     0.973       FG\n cartap     0.9545 0.0145 Inf    0.8871     0.982        G\n pirate     0.9545 0.0145 Inf    0.8871     0.982        G\n delegate   0.9545 0.0145 Inf    0.8871     0.982        G\n joiner     0.9545 0.0145 Inf    0.8871     0.982        G\n abamex     0.9545 0.0145 Inf    0.8871     0.982        G\n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 16 estimates \nIntervals are back-transformed from the logit scale \nP value adjustment: tukey method for comparing a family of 16 estimates \nTests are performed on the log odds ratio scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld_df &lt;- as.data.frame(cld_results) |&gt; \n  dplyr::rename(group_sig = .group,\n                emmean = prob,\n                lower.CL = asymp.LCL,\n                upper.CL = asymp.UCL)\n\ncld_df &lt;- cld_df |&gt;\n  mutate(tratamento = str_to_sentence(tratamento))\n\n\nggplot(cld_df, aes(x = reorder(tratamento, emmean), y = emmean, fill = group_sig)) + \n  geom_bar(stat = \"identity\", fill = \"darkgreen\", color = \"black\") +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2, position = position_dodge(0.9)) +\n  geom_text(aes(y = upper.CL, label = group_sig),\n          vjust = -0.5, size = 4, color = \"black\")+\n  labs(title = \"Probabilidade estimada de resposta por tratamento (GLM Quasibinomial)\",\n       x = \"Tratamentos\",\n       y = \"Probabilidade estimada (EMM)\") +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  ylim(0, max(cld_df$upper.CL) * 1)\n\n\n\n\n\n\n\n\n\ndispersion_param_quasibinomial &lt;- summary(modelo_glm_qb)$dispersion\nprint(dispersion_param_quasibinomial)\n\n[1] 0.3183159\n\n\nO valor 0.3183159 indica que os dados têm menos variabilidade (subdispersão) do que o observado pelo modelo binomial simples. O modelo quasibinomial utiliza esse valor para ajustar os p-valores e erros padrão, tornando a análise mais precisa.\n\n\nGLMM - Modelo linear generalizado misto\nO GLMM é apropriado para os dados, porque a variável é binomial (mortos / vivos), tem um efeito fixo a ser testado (tratamentos) e possui efeitos aleatórios (repetições).\n\ndados$repetição &lt;- as.factor(dados$repetição)\n\ndados$resposta_binomial &lt;- cbind(dados$mortos, dados$vivos)\n\nmodelo_glmm &lt;- glmer(resposta_binomial ~ tratamento + (1 | repetição),\n                     family = binomial(link = \"logit\"),\n                     data = dados_ajustados)\n\nsummary(modelo_glmm)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: resposta_binomial ~ tratamento + (1 | repetição)\n   Data: dados_ajustados\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n    261.4     305.0    -113.7     227.4        79 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.2917 -0.1526  0.5160  0.5299  2.3622 \n\nRandom effects:\n Groups    Name        Variance  Std.Dev.\n repetição (Intercept) 6.904e-05 0.008309\nNumber of obs: 96, groups:  repetição, 6\n\nFixed effects:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)          2.6733     0.5009   5.337 9.43e-08 ***\ntratamentoactara    -2.7346     0.5581  -4.900 9.61e-07 ***\ntratamentoavatar    -0.3887     0.6569  -0.592 0.554011    \ntratamentobelt      -0.3751     0.6584  -0.570 0.568923    \ntratamentobenevia   -1.9130     0.5663  -3.378 0.000729 ***\ntratamentocartap    -0.3704     0.6590  -0.562 0.574026    \ntratamentocontrole  -6.3354     0.9336  -6.786 1.15e-11 ***\ntratamentodelegate  -0.3598     0.6602  -0.545 0.585745    \ntratamentohayate    -1.3913     0.5831  -2.386 0.017021 *  \ntratamentojoiner    -0.3946     0.6562  -0.601 0.547622    \ntratamentonomolt    -1.7774     0.6211  -2.862 0.004216 ** \ntratamentopirate    -0.3672     0.6593  -0.557 0.577625    \ntratamentopremio    -1.8524     0.5677  -3.263 0.001102 ** \ntratamentotalstar   -0.4441     0.6508  -0.682 0.494997    \ntratamentotracer    -0.6936     0.6269  -1.106 0.268522    \ntratamentovertimec  -0.3731     0.6587  -0.566 0.571119    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.573179 (tol = 0.002, component 1)\n\nemm &lt;- emmeans(modelo_glmm, ~ tratamento, type = \"response\")\nletras &lt;- cld(emm, adjust = \"tukey\", Letters = LETTERS)\n\nprint(letras)\n\n tratamento  prob     SE  df asymp.LCL asymp.UCL .group\n controle   0.025 0.0192 Inf   0.00251     0.208  A    \n actara     0.485 0.0615 Inf   0.31272     0.660   B   \n benevia    0.681 0.0574 Inf   0.49538     0.823   BC  \n premio     0.694 0.0567 Inf   0.50829     0.833   BC  \n nomolt     0.710 0.0756 Inf   0.45340     0.879   BC  \n hayate     0.783 0.0508 Inf   0.59916     0.897    C  \n tracer     0.879 0.0402 Inf   0.70443     0.957    C  \n talstar    0.903 0.0365 Inf   0.73186     0.969    C  \n joiner     0.907 0.0357 Inf   0.73667     0.971    C  \n avatar     0.908 0.0356 Inf   0.73723     0.972    C  \n belt       0.909 0.0354 Inf   0.73852     0.972    C  \n vertimec   0.909 0.0354 Inf   0.73871     0.972    C  \n cartap     0.909 0.0354 Inf   0.73896     0.972    C  \n pirate     0.909 0.0353 Inf   0.73926     0.973    C  \n delegate   0.910 0.0352 Inf   0.73994     0.973    C  \n abamex     0.935 0.0303 Inf   0.76797     0.984    C  \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 16 estimates \nIntervals are back-transformed from the logit scale \nP value adjustment: tukey method for comparing a family of 16 estimates \nTests are performed on the log odds ratio scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nletras &lt;- letras |&gt;\n  mutate(tratamento = str_to_sentence(tratamento))\n\nggplot(as.data.frame(letras), aes(x = reorder (tratamento, prob), y = prob)) +\n  geom_col(fill = \"darkgreen\", color = \"black\") +\n  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), width = 0.2) +\n  geom_text(aes(y = asymp.UCL, label = .group),\n          vjust = -0.5, size = 4, color = \"black\") +\n  labs(title = \"Proporção de insetos mortos por tratamento (GLMM)\",\n         y = \"Proporção estimada de mortos\", x = \"Tratamentos\") +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  ylim(0, max(cld_df$upper.CL) * 1.05)\n\n\n\n\n\n\n\n\n\ndispersion_param_glmm &lt;- sum(residuals(modelo_glmm, type = \"pearson\")^2) / df.residual(modelo_glmm)\nprint(dispersion_param_glmm)\n\n[1] 0.4918094\n\n\nO modelo apresentou um parâmetro de dispersão de 0.4918094. Este valor, é inferior a 1, indicando claramente a presença de subdispersão nos dados, ou seja, a variabilidade observada é menor do que a esperada pela distribuição binomial padrão. Assim é necessário o ajuste do argumento.\nDispformula: o modelo GLMM foi ajustado utilizando o argumento dispformula = ~1, que permite estimar um um valor de dispersão diferente do padrão. Assim, ele permite inferências mais precisas.\n\ndados_ajustados$mortos_ajustados &lt;- ceiling(dados_ajustados$mortos_ajustados)\ndados_ajustados$vivos_ajustados &lt;- ceiling(dados_ajustados$vivos_ajustados)\n\nmodelo_glmm_disp &lt;- glmmTMB(cbind(mortos_ajustados, vivos_ajustados) ~ tratamento + (1 | repetição),\n                          family = binomial(link = \"logit\"),\n                          data = dados_ajustados, \n                          dispformula = ~1)\n\nsummary(modelo_glmm_disp)\n\n Family: binomial  ( logit )\nFormula:          cbind(mortos_ajustados, vivos_ajustados) ~ tratamento + (1 |  \n    repetição)\nData: dados_ajustados\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n    269.5     313.1    -117.7     235.5        79 \n\nRandom effects:\n\nConditional model:\n Groups    Name        Variance  Std.Dev. \n repetição (Intercept) 1.973e-10 1.405e-05\nNumber of obs: 96, groups:  repetição, 6\n\nConditional model:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)         2.398e+00  4.264e-01   5.624 1.87e-08 ***\ntratamentoactara   -2.398e+00  4.872e-01  -4.922 8.58e-07 ***\ntratamentoavatar   -5.733e-01  5.458e-01  -1.050 0.293543    \ntratamentobelt     -4.520e-01  5.557e-01  -0.813 0.416010    \ntratamentobenevia  -1.642e+00  4.957e-01  -3.312 0.000927 ***\ntratamentocartap   -1.989e-05  6.030e-01   0.000 0.999974    \ntratamentocontrole -4.626e+00  5.831e-01  -7.933 2.13e-15 ***\ntratamentodelegate  1.715e-05  6.030e-01   0.000 0.999977    \ntratamentohayate   -1.063e+00  5.158e-01  -2.061 0.039327 *  \ntratamentojoiner   -1.189e-06  6.030e-01   0.000 0.999998    \ntratamentonomolt   -1.596e+00  5.415e-01  -2.947 0.003214 ** \ntratamentopirate    3.850e-06  6.030e-01   0.000 0.999995    \ntratamentopremio   -1.577e+00  4.973e-01  -3.171 0.001518 ** \ntratamentotalstar  -1.694e-01  5.831e-01  -0.291 0.771415    \ntratamentotracer   -8.853e-01  5.251e-01  -1.686 0.091777 .  \ntratamentovertimec -3.185e-01  5.678e-01  -0.561 0.574924    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\noverdisp_check &lt;- performance::check_overdispersion(modelo_glmm_disp)\nprint(overdisp_check)\n\n# Overdispersion test\n\n dispersion ratio = 0.863\n          p-value = 0.088\n\nemm &lt;- emmeans(modelo_glmm_disp, ~ tratamento, type = \"response\")\nprint(emm)\n\n tratamento   prob     SE  df asymp.LCL asymp.UCL\n abamex     0.9167 0.0326 Inf    0.8267     0.962\n actara     0.5000 0.0589 Inf    0.3865     0.613\n avatar     0.8611 0.0408 Inf    0.7607     0.924\n belt       0.8750 0.0390 Inf    0.7769     0.934\n benevia    0.6806 0.0549 Inf    0.5649     0.778\n cartap     0.9167 0.0326 Inf    0.8267     0.962\n controle   0.0972 0.0349 Inf    0.0471     0.190\n delegate   0.9167 0.0326 Inf    0.8267     0.962\n hayate     0.7917 0.0479 Inf    0.6827     0.870\n joiner     0.9167 0.0326 Inf    0.8267     0.962\n nomolt     0.6905 0.0713 Inf    0.5370     0.811\n pirate     0.9167 0.0326 Inf    0.8267     0.962\n premio     0.6944 0.0543 Inf    0.5792     0.790\n talstar    0.9028 0.0349 Inf    0.8098     0.953\n tracer     0.8194 0.0453 Inf    0.7134     0.892\n vertimec   0.8889 0.0370 Inf    0.7932     0.943\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the logit scale \n\nletras &lt;- cld(emm, adjust = \"tukey\", Letters = LETTERS)\nprint(letras)\n\n tratamento   prob     SE  df asymp.LCL asymp.UCL .group\n controle   0.0972 0.0349 Inf    0.0323     0.258  A    \n actara     0.5000 0.0589 Inf    0.3330     0.667   B   \n benevia    0.6806 0.0549 Inf    0.5028     0.818   BC  \n nomolt     0.6905 0.0713 Inf    0.4547     0.856   BC  \n premio     0.6944 0.0543 Inf    0.5167     0.829   BC  \n hayate     0.7917 0.0479 Inf    0.6176     0.899    C  \n tracer     0.8194 0.0453 Inf    0.6478     0.918    C  \n avatar     0.8611 0.0408 Inf    0.6942     0.944    C  \n belt       0.8750 0.0390 Inf    0.7100     0.952    C  \n vertimec   0.8889 0.0370 Inf    0.7259     0.960    C  \n talstar    0.9028 0.0349 Inf    0.7419     0.968    C  \n cartap     0.9167 0.0326 Inf    0.7579     0.975    C  \n joiner     0.9167 0.0326 Inf    0.7579     0.975    C  \n abamex     0.9167 0.0326 Inf    0.7579     0.975    C  \n pirate     0.9167 0.0326 Inf    0.7579     0.975    C  \n delegate   0.9167 0.0326 Inf    0.7579     0.975    C  \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 16 estimates \nIntervals are back-transformed from the logit scale \nP value adjustment: tukey method for comparing a family of 16 estimates \nTests are performed on the log odds ratio scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nletras_df &lt;- as.data.frame(letras) |&gt;\ndplyr::rename(group_sig = .group,\nemmean = prob,\nlower.CL = asymp.LCL,\nupper.CL = asymp.UCL)\n\nletras_df &lt;- letras_df |&gt;\n  mutate(\n    grupo = case_when(\n      tratamento == \"Controle\" ~ \"Controle\",\n      emmean &lt; 0.3 ~ \"Grupo Baixa Mortalidade\",\n      emmean &gt;= 0.3 & emmean &lt; 0.6 ~ \"Grupo Média Mortalidade\",\n      emmean &gt;= 0.6 ~ \"Grupo Alta Mortalidade\",\n      TRUE ~ \"Outros\" \n    )\n  )\n\nletras_df &lt;- letras_df |&gt;\nmutate(tratamento = str_to_sentence(tratamento))\n\ngraf_glmm &lt;- ggplot(letras_df, aes(x = reorder(tratamento, emmean), y = emmean, fill = grupo)) +\ngeom_bar(stat = \"identity\", color = \"black\") +\ngeom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2, position = position_dodge(0.9)) +\ngeom_text(aes(y = upper.CL, label = group_sig),\nvjust = -0.5, size = 4, color = \"black\", fontface = \"bold\") +\nlabs(title = \"Proporção de insetos mortos por tratamento (GLMM Binomial com dispersão)\", \nx = \"Tratamentos\",\ny = \"Proporção estimada de mortos\",\nfill = \"Grupos de tratamento\") +\ntheme_classic() +\ntheme(plot.title = element_text(hjust = 0.5, face = \"bold\"),\naxis.text.x = element_text(angle = 45, hjust = 1, size = 9)) +\nylim(0, max(letras_df$upper.CL) * 1.05) +\ncoord_flip() +\nscale_fill_manual(values = c(\n\"Controle\" = \"grey\",\n\"Grupo Baixa Mortalidade\" = \"#99d594\",\n\"Grupo Média Mortalidade\" = \"#67a9cf\",\n\"Grupo Alta Mortalidade\" = \"#af8dc3\",\n\"Outros\" = \"lightgrey\"\n))\n\nprint(graf_glmm)\n\n\n\n\n\n\n\n\n\ndispersion_param_modelado &lt;- sigma(modelo_glmm_disp)\nprint(paste(\"Parâmetro de dispersão (sigma) para Binomial com dispformula:\", dispersion_param_modelado))\n\n[1] \"Parâmetro de dispersão (sigma) para Binomial com dispformula: 1\"\n\n\nNo modelo GLMM ajustado com glmmTMB e família binomial possui parâmetro de dispersão de 1. Isso indica que, ao considerar os efeitos fixos e aleatórios, a variabilidade em seus dados está perfeitamente alinhada com o que a distribuição binomial prevê. Portanto, não há superdispersão nem subdispersão residual, e as inferências (p-valores e erros padrão) do seu modelo são consideradas válidas e precisas.\n\n\nComparação dos modelos\n\nCompação do índice de dispersão\nFoi realizada a comparação do modelo GLM com distribuição quasibinomial e o modelo GLMM binomial com dispformula. O índice de dispersão do GLM foi de 0.318, indicando subdispersão, ou seja, variação abaixo da esperada, o que pode comprometer a validade estatística dos testes. Já o GLMM apresentou índice de dispersão de 0.863, próximo de 1, o que indica um ajuste mais adequado à variância dos dados. Portanto, o GLMM com dispersão é mais adequado por fornecer estimativas mais robustas e realistas para a inferência dos efeitos dos tratamentos.\n\ndisp_glm &lt;- sum(residuals(modelo_glm_qb, type = \"pearson\")^2) / df.residual(modelo_glm_qb)\n\ndisp_glmm &lt;- check_overdispersion(modelo_glmm_disp)\n\ncat(\"GLM quasibinomial - Índice de dispersão:\", round(disp_glm, 3), \"\\n\")\n\nGLM quasibinomial - Índice de dispersão: 0.318 \n\ncat(\"GLMM binomial - Índice de dispersão:\", round(disp_glmm$dispersion_ratio, 3), \"\\n\")\n\nGLMM binomial - Índice de dispersão: 0.863 \n\n\n\n\nModelo selecionado\n\nprint(graf_glmm)"
  },
  {
    "objectID": "analises.html#curva-de-probit",
    "href": "analises.html#curva-de-probit",
    "title": "Análise dos dados do experimento de eficiência de inseticidas no controle de lagartas da traça-do-tomateiro",
    "section": "Curva de Probit",
    "text": "Curva de Probit\nA Curva de Probit foi feita para os inseticidas abamex, avatar, benevia, delegate e joiner. A Curva de Probit é um modelo de regressão onde a reposta binária (morto / vivo) é transformada pela função probit para ajustar uma relação linear com a dose transformada em log. Comum para cálculo da CL50.\n\nAbamex\n\ndados_ab &lt;- data.frame(\n  conc = c(25, 50, 5, 40, 10, 1),      \n  total = c(60, 60, 60, 60, 60, 60),                   \n  mortos = c(36, 56, 17, 41, 27, 8)     \n)\n\ndados_ab$mort_prop &lt;- dados_ab$mortos / dados_ab$total \ndados_ab$lconc &lt;- log10(dados_ab$conc)             \n\nprint(\"Dados Iniciais:\")\n\n[1] \"Dados Iniciais:\"\n\nprint(dados_ab)\n\n  conc total mortos mort_prop   lconc\n1   25    60     36 0.6000000 1.39794\n2   50    60     56 0.9333333 1.69897\n3    5    60     17 0.2833333 0.69897\n4   40    60     41 0.6833333 1.60206\n5   10    60     27 0.4500000 1.00000\n6    1    60      8 0.1333333 0.00000\n\nmodelo_reg_ab &lt;- lm(mort_prop ~ lconc, data = dados_ab)\n\nprint(anova(modelo_reg_ab))\n\nAnalysis of Variance Table\n\nResponse: mort_prop\n          Df  Sum Sq Mean Sq F value   Pr(&gt;F)   \nlconc      1 0.37296 0.37296  36.247 0.003834 **\nResiduals  4 0.04116 0.01029                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nprint(summary(modelo_reg_ab))\n\n\nCall:\nlm(formula = mort_prop ~ lconc, data = dados_ab)\n\nResiduals:\n       1        2        3        4        5        6 \n-0.05453  0.15114 -0.07476 -0.05776 -0.03576  0.07167 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  0.06166    0.08577   0.719  0.51197   \nlconc        0.42410    0.07044   6.021  0.00383 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1014 on 4 degrees of freedom\nMultiple R-squared:  0.9006,    Adjusted R-squared:  0.8758 \nF-statistic: 36.25 on 1 and 4 DF,  p-value: 0.003834\n\nmodelo_probit_ab &lt;- glm(\n  cbind(mortos, total - mortos) ~ lconc,\n  data = dados_ab,\n  family = binomial(link = \"probit\")\n)\n\nprint(summary(modelo_probit_ab))\n\n\nCall:\nglm(formula = cbind(mortos, total - mortos) ~ lconc, family = binomial(link = \"probit\"), \n    data = dados_ab)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.3277     0.1727   -7.69 1.47e-14 ***\nlconc         1.2559     0.1391    9.03  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 112.489  on 5  degrees of freedom\nResidual deviance:  13.834  on 4  degrees of freedom\nAIC: 42.645\n\nNumber of Fisher Scoring iterations: 4\n\npearson_chisq_ab &lt;- sum(residuals(modelo_probit_ab, type = \"pearson\")^2)\ndf_chisq_ab &lt;- nrow(dados_ab) - length(coef(modelo_probit_ab))\np_valor_chisq_ab &lt;- pchisq(pearson_chisq_ab, df = df_chisq_ab, lower.tail = FALSE)\n\ncat(paste(\"Estatística Qui-quadrado de Pearson:\", round(pearson_chisq_ab, 4), \"\\n\"))\n\nEstatística Qui-quadrado de Pearson: 12.0059 \n\ncat(paste(\"Graus de Liberdade (DF):\", df_chisq_ab, \"\\n\"))\n\nGraus de Liberdade (DF): 4 \n\ncat(paste(\"Pr &gt; ChiSq (p-valor):\", round(p_valor_chisq_ab, 4), \"\\n\\n\"))\n\nPr &gt; ChiSq (p-valor): 0.0173 \n\nprobabilidades_ab &lt;- c(\n  seq(from = 0.01, to = 0.10, by = 0.01),\n  seq(from = 0.15, to = 0.90, by = 0.05),\n  seq(from = 0.91, to = 0.99, by = 0.01)\n)\n\ncl_log_ab &lt;- dose.p(modelo_probit_ab, p = probabilidades_ab)\nerros_padrao_log_ab &lt;- attr(cl_log_ab, \"SE\")\nz_valor_ab &lt;- qnorm(0.975) \nlimite_inf_log_ab &lt;- cl_log_ab - z_valor_ab * erros_padrao_log_ab\nlimite_sup_log_ab &lt;- cl_log_ab + z_valor_ab * erros_padrao_log_ab\n\ntabela_escala_log10_ab &lt;- data.frame(\n  Probabilidade = probabilidades_ab,\n  Log10_conc = cl_log_ab,\n  Limite_Inferior_95 = limite_inf_log_ab,\n  Limite_Superior_95 = limite_sup_log_ab\n)\n\ntabela_escala_conc_ab &lt;- data.frame(\n  Probabilidade = probabilidades_ab,\n  Concentracao = 10^cl_log_ab,\n  Limite_Inferior_95 = 10^limite_inf_log_ab,\n  Limite_Superior_95 = 10^limite_sup_log_ab\n)\n\noptions(digits = 6) \n\nprint(tabela_escala_log10_ab)\n\n          Probabilidade Log10_conc Limite_Inferior_95 Limite_Superior_95\np = 0.01:          0.01 -0.7951538        -1.22739826       -0.362909326\np = 0.02:          0.02 -0.5780975        -0.96506165       -0.191133407\np = 0.03:          0.03 -0.4403823        -0.79886222       -0.081902361\np = 0.04:          0.04 -0.3367845        -0.67399734        0.000428382\np = 0.05:          0.05 -0.2525157        -0.57255226        0.067520960\np = 0.06:          0.06 -0.1807896        -0.48630846        0.124729171\np = 0.07:          0.07 -0.1179000        -0.41077828        0.174978340\np = 0.08:          0.08 -0.0615898        -0.34322997        0.220050443\np = 0.09:          0.09 -0.0103779        -0.28187131        0.261115540\np = 0.10:          0.10  0.0367627        -0.22545999        0.298985453\np = 0.15:          0.15  0.2319375         0.00720882        0.456666155\np = 0.20:          0.20  0.3870562         0.19070952        0.583402870\np = 0.25:          0.25  0.5201342         0.34662370        0.693644762\np = 0.30:          0.30  0.6396424         0.48490696        0.794377881\np = 0.35:          0.35  0.7503846         0.61098060        0.889788545\np = 0.40:          0.40  0.8554680         0.72809962        0.982836463\np = 0.45:          0.45  0.9571375         0.83836664        1.075908390\np = 0.50:          0.50  1.0571951         0.94328837        1.171101749\np = 0.55:          0.55  1.1572526         1.04417649        1.270328710\np = 0.60:          0.60  1.2589221         1.14247116        1.375372992\np = 0.65:          0.65  1.3640055         1.23996952        1.488041569\np = 0.70:          0.70  1.4747477         1.33897868        1.610516713\np = 0.75:          0.75  1.5942559         1.44253545        1.745976327\np = 0.80:          0.80  1.7273339         1.55497045        1.899697401\np = 0.85:          0.85  1.8824526         1.68342186        2.081483404\np = 0.90:          0.90  2.0776274         1.84247724        2.312777530\np = 0.91:          0.91  2.1247680         1.88059292        2.368943083\np = 0.92:          0.92  2.1759799         1.92189677        2.430062992\np = 0.93:          0.93  2.2322901         1.96720203        2.497378147\np = 0.94:          0.94  2.2951798         2.01768047        2.572679060\np = 0.95:          0.95  2.3669058         2.07511632        2.658695220\np = 0.96:          0.96  2.4511746         2.14243816        2.759911038\np = 0.97:          0.97  2.5547724         2.22500506        2.884539759\np = 0.98:          0.98  2.6924876         2.33448953        3.050485764\np = 0.99:          0.99  2.9095439         2.50656436        3.312523467\n\nprint(tabela_escala_conc_ab)\n\n          Probabilidade Concentracao Limite_Inferior_95 Limite_Superior_95\np = 0.01:          0.01     0.160268          0.0592382           0.433601\np = 0.02:          0.02     0.264182          0.1083773           0.643971\np = 0.03:          0.03     0.362759          0.1589051           0.828128\np = 0.04:          0.04     0.460485          0.2118374           1.000987\np = 0.05:          0.05     0.559093          0.2675764           1.168210\np = 0.06:          0.06     0.659493          0.3263560           1.332690\np = 0.07:          0.07     0.762255          0.3883486           1.496161\np = 0.08:          0.08     0.867781          0.4537013           1.659780\np = 0.09:          0.09     0.976387          0.5225510           1.824381\np = 0.10:          0.10     1.088335          0.5950316           1.990607\np = 0.15:          0.15     1.705837          1.0167374           2.861977\np = 0.20:          0.20     2.438126          1.5513490           3.831800\np = 0.25:          0.25     3.312335          2.2213843           4.939065\np = 0.30:          0.30     4.361566          3.0542668           6.228420\np = 0.35:          0.35     5.628395          4.0830115           7.758693\np = 0.40:          0.40     7.169156          5.3468700           9.612502\np = 0.45:          0.45     9.060194          6.8923392          11.909908\np = 0.50:          0.50    11.407620          8.7758334          14.828655\np = 0.55:          0.55    14.363246         11.0707360          18.634971\np = 0.60:          0.60    18.151899         13.8826112          23.734112\np = 0.65:          0.65    23.120943         17.3767889          30.763913\np = 0.70:          0.70    29.836488         21.8262276          40.786526\np = 0.75:          0.75    39.287635         27.7035515          55.715538\np = 0.80:          0.80    53.374513         35.8897514          79.377497\np = 0.85:          0.85    76.287368         48.2416175         120.637799\np = 0.90:          0.90   119.571420         69.5788491         205.483772\np = 0.91:          0.91   133.280927         75.9613937         233.853074\np = 0.92:          0.92   149.961537         83.5404427         269.192522\np = 0.93:          0.93   170.722235         92.7261068         314.324438\np = 0.94:          0.94   197.323933        104.1550825         373.834226\np = 0.95:          0.95   232.758619        118.8820601         455.716989\np = 0.96:          0.96   282.601588        138.8155627         575.322075\np = 0.97:          0.97   358.733892        167.8823573         766.548713\np = 0.98:          0.98   492.592334        216.0177976        1123.274149\np = 0.99:          0.99   811.977346        321.0438527        2053.635989\n\nlconc_grafico_ab &lt;- data.frame(lconc = seq(0, max(dados_ab$lconc) + 0.1, length.out = 200))\n\npredicoes_ab &lt;- predict(modelo_probit_ab, newdata = lconc_grafico_ab, type = \"link\", se.fit = TRUE)\n\nz_valor_ab &lt;- qnorm(0.975)\nlconc_grafico_ab$prob_predita_ab &lt;- pnorm(predicoes_ab$fit)\nlconc_grafico_ab$prob_superior_ab &lt;- pnorm(predicoes_ab$fit + z_valor_ab * predicoes_ab$se.fit)\nlconc_grafico_ab$prob_inferior_ab &lt;- pnorm(predicoes_ab$fit - z_valor_ab * predicoes_ab$se.fit)\n\n\nlc50_log_ab &lt;- as.numeric(dose.p(modelo_probit_ab, p = 0.50))\n\nlc50_conc_ab &lt;- 10^lc50_log_ab\n\nx_lim_inferior_ab &lt;- -1.5 \nx_lim_superior_ab &lt;- 1    \n\nlconc_grafico_ab &lt;- data.frame(lconc = seq(x_lim_inferior_ab, x_lim_superior_ab, length.out = 200))\n\npredicoes_ab &lt;- predict(modelo_probit_ab, newdata = lconc_grafico_ab, type = \"link\", se.fit = TRUE)\nz_valor_ab &lt;- qnorm(0.975)\nlconc_grafico_ab$prob_predita_ab &lt;- pnorm(predicoes_ab$fit)\nlconc_grafico_ab$prob_superior_ab &lt;- pnorm(predicoes_ab$fit + z_valor_ab * predicoes_ab$se.fit)\nlconc_grafico_ab$prob_inferior &lt;- pnorm(predicoes_ab$fit - z_valor_ab * predicoes_ab$se.fit)\n\ngrafico_probit_final_ab &lt;- ggplot() +\n  geom_ribbon(data = lconc_grafico_ab,\n              aes(x = lconc, ymin = prob_inferior * 100, ymax = prob_superior_ab * 100),\n              fill = \"skyblue\", alpha = 0.5) +\n  geom_line(data = lconc_grafico_ab,\n            aes(x = lconc, y = prob_predita_ab * 100),\n            color = \"blue\", size = 1) +\n  geom_point(data = dados_ab,\n             aes(x = lconc, y = mort_prop * 100),\n             color = \"red\", size = 4) +\n  geom_hline(yintercept = 50, linetype = \"dashed\", color = \"black\", size = 0.7) +\n  geom_vline(xintercept = lc50_log_ab, linetype = \"dashed\", color = \"black\", size = 0.7) +\n  labs(\n    title = \"Curva dose-resposta (Modelo Probit) - Abamex\",\n    x = \"Log10 (Concentração)\",\n    y = \"Mortalidade observada e prevista (%)\"\n  ) +\n  annotate(\"text\", \n           x = lc50_log_ab, \n           y = 45, \n           label = paste(\"LC50 =\", format(lc50_conc_ab, digits = 4)), \n           hjust = -0.1,\n           vjust = 1,\n           fontface = \"bold\",\n           color = \"black\") +\n  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 10), expand = c(0, 0)) +\n  scale_x_continuous(limits = c(x_lim_inferior_ab, x_lim_superior_ab), breaks = seq(-4, 1, 0.5)) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\nprint(grafico_probit_final_ab)\n\n\n\n\n\n\n\n\n\n\nAvatar\n\ndados_av &lt;- data.frame(\n  conc = c(0.1, 1, 5, 10, 25, 40, 0.3, 0.5, 0.7),      \n  total = c(60, 60, 60, 60, 60, 60, 60, 60, 60),                   \n  mortos = c(0, 4, 16, 1, 15, 14, 3, 8, 6)     \n)\n\ndados_av$mort_prop_av &lt;- dados_av$mortos / dados_av$total \ndados_av$lconc_av &lt;- log10(dados_av$conc)             \n\nprint(\"Dados Iniciais:\")\n\n[1] \"Dados Iniciais:\"\n\nprint(dados_av)\n\n  conc total mortos mort_prop_av  lconc_av\n1  0.1    60      0    0.0000000 -1.000000\n2  1.0    60      4    0.0666667  0.000000\n3  5.0    60     16    0.2666667  0.698970\n4 10.0    60      1    0.0166667  1.000000\n5 25.0    60     15    0.2500000  1.397940\n6 40.0    60     14    0.2333333  1.602060\n7  0.3    60      3    0.0500000 -0.522879\n8  0.5    60      8    0.1333333 -0.301030\n9  0.7    60      6    0.1000000 -0.154902\n\nmodelo_reg_av &lt;- lm(mort_prop_av ~ lconc_av, data = dados_av)\n\nprint(anova(modelo_reg_av))\n\nAnalysis of Variance Table\n\nResponse: mort_prop_av\n          Df  Sum Sq Mean Sq F value Pr(&gt;F)  \nlconc_av   1 0.03911 0.03911    6.03 0.0438 *\nResiduals  7 0.04540 0.00649                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nprint(summary(modelo_reg_av))\n\n\nCall:\nlm(formula = mort_prop_av ~ lconc_av, data = dados_av)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.16122 -0.02365  0.00902  0.04143  0.11200 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   0.1008     0.0285    3.54   0.0095 **\nlconc_av      0.0771     0.0314    2.46   0.0438 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0805 on 7 degrees of freedom\nMultiple R-squared:  0.463, Adjusted R-squared:  0.386 \nF-statistic: 6.03 on 1 and 7 DF,  p-value: 0.0438\n\nmodelo_probit_av &lt;- glm(\n  cbind(mortos, total - mortos) ~ lconc_av,\n  data = dados_av,\n  family = binomial(link = \"probit\")\n)\n\nprint(summary(modelo_probit_av))\n\n\nCall:\nglm(formula = cbind(mortos, total - mortos) ~ lconc_av, family = binomial(link = \"probit\"), \n    data = dados_av)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.3420     0.0864  -15.54  &lt; 2e-16 ***\nlconc_av      0.3982     0.0858    4.64  3.4e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 53.183  on 8  degrees of freedom\nResidual deviance: 30.874  on 7  degrees of freedom\nAIC: 63.15\n\nNumber of Fisher Scoring iterations: 4\n\npearson_chisq_av &lt;- sum(residuals(modelo_probit_av, type = \"pearson\")^2)\ndf_chisq_av &lt;- nrow(dados_av) - length(coef(modelo_probit_av))\np_valor_chisq_av &lt;- pchisq(pearson_chisq_av, df = df_chisq_av, lower.tail = FALSE)\n\ncat(paste(\"Estatística Qui-quadrado de Pearson:\", round(pearson_chisq_av, 4), \"\\n\"))\n\nEstatística Qui-quadrado de Pearson: 24.7946 \n\ncat(paste(\"Graus de Liberdade (DF):\", df_chisq_av, \"\\n\"))\n\nGraus de Liberdade (DF): 7 \n\ncat(paste(\"Pr &gt; ChiSq (p-valor):\", round(p_valor_chisq_av, 4), \"\\n\\n\"))\n\nPr &gt; ChiSq (p-valor): 8e-04 \n\nprobabilidades_av &lt;- c(\n  seq(from = 0.01, to = 0.10, by = 0.01),\n  seq(from = 0.15, to = 0.90, by = 0.05),\n  seq(from = 0.91, to = 0.99, by = 0.01)\n)\n\ncl_log_av &lt;- dose.p(modelo_probit_av, p = probabilidades_av)\nerros_padrao_log_av &lt;- attr(cl_log_av, \"SE\")\nz_valor_av &lt;- qnorm(0.975) \nlimite_inf_log_av &lt;- cl_log_av - z_valor_av * erros_padrao_log_av\nlimite_sup_log_av &lt;- cl_log_av + z_valor_av * erros_padrao_log_av\n\ntabela_escala_log10_av &lt;- data.frame(\n  Probabilidade = probabilidades_av,\n  Log10_conc = cl_log_av,\n  Limite_Inferior_95 = limite_inf_log_av,\n  Limite_Superior_95 = limite_sup_log_av\n)\n\ntabela_escala_conc_av &lt;- data.frame(\n  Probabilidade = probabilidades_av,\n  Concentracao = 10^cl_log_av,\n  Limite_Inferior_95 = 10^limite_inf_log_av,\n  Limite_Superior_95 = 10^limite_sup_log_av\n)\n\noptions(digits = 6) \n\nprint(tabela_escala_log10_av)\n\n          Probabilidade  Log10_conc Limite_Inferior_95 Limite_Superior_95\np = 0.01:          0.01 -2.47191568          -3.801554         -1.1422769\np = 0.02:          0.02 -1.78732722          -2.841054         -0.7336000\np = 0.03:          0.03 -1.35297778          -2.235993         -0.4699627\np = 0.04:          0.04 -1.02623362          -1.784726         -0.2677412\np = 0.05:          0.05 -0.76045246          -1.421591         -0.0993141\np = 0.06:          0.06 -0.53423094          -1.116726          0.0482641\np = 0.07:          0.07 -0.33587892          -0.854099          0.1823410\np = 0.08:          0.08 -0.15827835          -0.624221          0.3076640\np = 0.09:          0.09  0.00324226          -0.421105          0.4275900\np = 0.10:          0.10  0.15192226          -0.240763          0.5446074\np = 0.15:          0.15  0.76749714           0.405663          1.1293311\np = 0.20:          0.20  1.25673655           0.799861          1.7136125\np = 0.25:          0.25  1.67646040           1.090396          2.2625246\np = 0.30:          0.30  2.05338538           1.333682          2.7730886\np = 0.35:          0.35  2.40266256           1.551269          3.2540557\np = 0.40:          0.40  2.73409244           1.753585          3.7146003\np = 0.45:          0.45  3.05475469           1.946831          4.1626785\np = 0.50:          0.50  3.37033296           2.135362          4.6053037\np = 0.55:          0.55  3.68591122           2.322716          5.0491063\np = 0.60:          0.60  4.00657347           2.512194          5.5009526\np = 0.65:          0.65  4.33800335           2.707318          5.9686887\np = 0.70:          0.70  4.68728053           2.912343          6.4622180\np = 0.75:          0.75  5.06420551           3.133058          6.9953534\np = 0.80:          0.80  5.48392936           3.378323          7.5895356\np = 0.85:          0.85  5.97316877           3.663688          8.2826493\np = 0.90:          0.90  6.58874366           4.022142          9.1553451\np = 0.91:          0.91  6.73742365           4.108639          9.3662080\np = 0.92:          0.92  6.89894426           4.202576          9.5953122\np = 0.93:          0.93  7.07654484           4.305831          9.8472583\np = 0.94:          0.94  7.27489685           4.421112         10.1286812\np = 0.95:          0.95  7.50111837           4.552546         10.4496909\np = 0.96:          0.96  7.76689954           4.706907         10.8268919\np = 0.97:          0.97  8.09364370           4.896601         11.2906866\np = 0.98:          0.98  8.52799313           5.148655         11.9073310\np = 0.99:          0.99  9.21258160           5.545711         12.8794519\n\nprint(tabela_escala_conc_av)\n\n          Probabilidade Concentracao Limite_Inferior_95 Limite_Superior_95\np = 0.01:          0.01  3.37353e-03        1.57923e-04        7.20648e-02\np = 0.02:          0.02  1.63182e-02        1.44193e-03        1.84672e-01\np = 0.03:          0.03  4.43631e-02        5.80774e-03        3.38873e-01\np = 0.04:          0.04  9.41383e-02        1.64163e-02        5.39832e-01\np = 0.05:          0.05  1.73599e-01        3.78799e-02        7.95584e-01\np = 0.06:          0.06  2.92260e-01        7.64318e-02        1.11754e+00\np = 0.07:          0.07  4.61446e-01        1.39927e-01        1.52174e+00\np = 0.08:          0.08  6.94579e-01        2.37563e-01        2.03079e+00\np = 0.09:          0.09  1.00749e+00        3.79223e-01        2.67664e+00\np = 0.10:          0.10  1.41880e+00        5.74430e-01        3.50435e+00\np = 0.15:          0.15  5.85460e+00        2.54486e+00        1.34689e+01\np = 0.20:          0.20  1.80608e+01        6.30755e+00        5.17145e+01\np = 0.25:          0.25  4.74745e+01        1.23139e+01        1.83031e+02\np = 0.30:          0.30  1.13080e+02        2.15617e+01        5.93046e+02\np = 0.35:          0.35  2.52733e+02        3.55852e+01        1.79496e+03\np = 0.40:          0.40  5.42116e+02        5.67002e+01        5.18323e+03\np = 0.45:          0.45  1.13437e+03        8.84771e+01        1.45438e+04\np = 0.50:          0.50  2.34603e+03        1.36572e+02        4.02999e+04\np = 0.55:          0.55  4.85189e+03        2.10240e+02        1.11971e+05\np = 0.60:          0.60  1.01525e+04        3.25233e+02        3.16922e+05\np = 0.65:          0.65  2.17773e+04        5.09704e+02        9.30441e+05\np = 0.70:          0.70  4.86721e+04        8.17228e+02        2.89880e+06\np = 0.75:          0.75  1.15933e+05        1.35849e+03        9.89358e+06\np = 0.80:          0.80  3.04740e+05        2.38959e+03        3.88629e+07\np = 0.85:          0.85  9.40089e+05        4.60987e+03        1.91712e+08\np = 0.90:          0.90  3.87921e+06        1.05231e+04        1.43003e+09\np = 0.91:          0.91  5.46290e+06        1.28422e+04        2.32385e+09\np = 0.92:          0.92  7.92400e+06        1.59432e+04        3.93833e+09\np = 0.93:          0.93  1.19274e+07        2.02223e+04        7.03491e+09\np = 0.94:          0.94  1.88320e+07        2.63701e+04        1.34487e+10\np = 0.95:          0.95  3.17043e+07        3.56899e+04        2.81638e+10\np = 0.96:          0.96  5.84655e+07        5.09222e+04        6.71262e+10\np = 0.97:          0.97  1.24063e+08        7.88135e+04        1.95293e+11\np = 0.98:          0.98  3.37282e+08        1.40817e+05        8.07850e+11\np = 0.99:          0.99  1.63148e+09        3.51327e+05        7.57621e+12\n\nlconc_grafico_av &lt;- data.frame(lconc_av = seq(0, max(dados_av$lconc_av) + 0.1, length.out = 200))\n\npredicoes_av &lt;- predict(modelo_probit_av, newdata = lconc_grafico_av, type = \"link\", se.fit = TRUE)\n\nz_valor_av &lt;- qnorm(0.975)\nlconc_grafico_av$prob_predita_av &lt;- pnorm(predicoes_av$fit)\nlconc_grafico_av$prob_superior_av &lt;- pnorm(predicoes_av$fit + z_valor_av * predicoes_av$se.fit)\nlconc_grafico_av$prob_inferior_ab &lt;- pnorm(predicoes_av$fit - z_valor_av * predicoes_av$se.fit)\n\nlc50_log_av &lt;- as.numeric(dose.p(modelo_probit_av, p = 0.50))\n\nlc50_conc_av &lt;- 10^lc50_log_av\n\nx_lim_inferior_av &lt;- -1.5 \nx_lim_superior_av &lt;- 1    \n\nlconc_grafico_av &lt;- data.frame(lconc_av = seq(x_lim_inferior_av, x_lim_superior_av, length.out = 200))\n\npredicoes_av &lt;- predict(modelo_probit_av, newdata = lconc_grafico_av, type = \"link\", se.fit = TRUE)\nz_valor_av &lt;- qnorm(0.975)\nlconc_grafico_av$prob_predita_av &lt;- pnorm(predicoes_av$fit)\nlconc_grafico_av$prob_superior_av &lt;- pnorm(predicoes_av$fit + z_valor_av * predicoes_av$se.fit)\nlconc_grafico_av$prob_inferior_av &lt;- pnorm(predicoes_av$fit - z_valor_av * predicoes_av$se.fit)\n\ngrafico_probit_final_av &lt;- ggplot() +\n  geom_ribbon(data = lconc_grafico_av,\n              aes(x = lconc_av, ymin = prob_inferior_av * 100, ymax = prob_superior_av * 100),\n              fill = \"skyblue\", alpha = 0.5) +\n  geom_line(data = lconc_grafico_av,\n            aes(x = lconc_av, y = prob_predita_av * 100),\n            color = \"blue\", size = 1) +\n  geom_point(data = dados_av,\n             aes(x = lconc_av, y = mort_prop_av * 100),\n             color = \"red\", size = 4) +\n  geom_hline(yintercept = 50, linetype = \"dashed\", color = \"black\", size = 0.7) +\n  geom_vline(xintercept = lc50_log_av, linetype = \"dashed\", color = \"black\", size = 0.7) +\n  labs(\n    title = \"Curva dose-resposta (Modelo Probit) - Avatar\",\n    x = \"Log10 (Concentração)\",\n    y = \"Mortalidade observada e prevista (%)\"\n  ) +\n  annotate(\"text\", \n           x = lc50_log_av, \n           y = 45, \n           label = paste(\"LC50 =\", format(lc50_conc_av, digits = 4)), \n           hjust = -0.1,\n           vjust = 1,\n           fontface = \"bold\",\n           color = \"black\") +\n  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 10), expand = c(0, 0)) +\n  scale_x_continuous(limits = c(x_lim_inferior_av, x_lim_superior_av), breaks = seq(-4, 1, 0.5)) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\nprint(grafico_probit_final_av)\n\n\n\n\n\n\n\n\n\n\nBenevia\n\ndados_be &lt;- data.frame(\n  conc = c(0.1, 1, 5, 10, 25, 40, 60),      \n  total = c(60, 60, 60, 60, 60, 50, 50),                   \n  mortos = c(1, 2, 8, 5, 44, 6, 8)     \n)\n\ndados_be$mort_prop_be &lt;- dados_be$mortos / dados_be$total \ndados_be$lconc_be &lt;- log10(dados_be$conc)             \n\nprint(\"Dados Iniciais:\")\n\n[1] \"Dados Iniciais:\"\n\nprint(dados_be)\n\n  conc total mortos mort_prop_be lconc_be\n1  0.1    60      1    0.0166667 -1.00000\n2  1.0    60      2    0.0333333  0.00000\n3  5.0    60      8    0.1333333  0.69897\n4 10.0    60      5    0.0833333  1.00000\n5 25.0    60     44    0.7333333  1.39794\n6 40.0    50      6    0.1200000  1.60206\n7 60.0    50      8    0.1600000  1.77815\n\nmodelo_reg_be &lt;- lm(mort_prop_be ~ lconc_be, data = dados_be)\n\nprint(anova(modelo_reg_be))\n\nAnalysis of Variance Table\n\nResponse: mort_prop_be\n          Df  Sum Sq Mean Sq F value Pr(&gt;F)\nlconc_be   1 0.07406 0.07406   1.252  0.314\nResiduals  5 0.29577 0.05915               \n\nprint(summary(modelo_reg_be))\n\n\nCall:\nlm(formula = mort_prop_be ~ lconc_be, data = dados_be)\n\nResiduals:\n      1       2       3       4       5       6       7 \n 0.0338 -0.0618 -0.0402 -0.1239  0.4814 -0.1548 -0.1346 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   0.0951     0.1208    0.79     0.47\nlconc_be      0.1122     0.1003    1.12     0.31\n\nResidual standard error: 0.243 on 5 degrees of freedom\nMultiple R-squared:   0.2,  Adjusted R-squared:  0.0403 \nF-statistic: 1.25 on 1 and 5 DF,  p-value: 0.314\n\nmodelo_probit_be &lt;- glm(\n  cbind(mortos, total - mortos) ~ lconc_be,\n  data = dados_be,\n  family = binomial(link = \"probit\")\n)\n\nprint(summary(modelo_probit_be))\n\n\nCall:\nglm(formula = cbind(mortos, total - mortos) ~ lconc_be, family = binomial(link = \"probit\"), \n    data = dados_be)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   -1.535      0.153  -10.03   &lt;2e-16 ***\nlconc_be       0.653      0.118    5.54    3e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 123.61  on 6  degrees of freedom\nResidual deviance:  82.54  on 5  degrees of freedom\nAIC: 109.9\n\nNumber of Fisher Scoring iterations: 4\n\npearson_chisq_be &lt;- sum(residuals(modelo_probit_be, type = \"pearson\")^2)\ndf_chisq_be &lt;- nrow(dados_be) - length(coef(modelo_probit_be))\np_valor_chisq_be &lt;- pchisq(pearson_chisq_be, df = df_chisq_be, lower.tail = FALSE)\n\ncat(paste(\"Estatística Qui-quadrado de Pearson:\", round(pearson_chisq_be, 4), \"\\n\"))\n\nEstatística Qui-quadrado de Pearson: 88.801 \n\ncat(paste(\"Graus de Liberdade (DF):\", df_chisq_be, \"\\n\"))\n\nGraus de Liberdade (DF): 5 \n\ncat(paste(\"Pr &gt; ChiSq (p-valor):\", round(p_valor_chisq_be, 4), \"\\n\\n\"))\n\nPr &gt; ChiSq (p-valor): 0 \n\nprobabilidades_be &lt;- c(\n  seq(from = 0.01, to = 0.10, by = 0.01),\n  seq(from = 0.15, to = 0.90, by = 0.05),\n  seq(from = 0.91, to = 0.99, by = 0.01)\n)\n\ncl_log_be &lt;- dose.p(modelo_probit_be, p = probabilidades_be)\nerros_padrao_log_be &lt;- attr(cl_log_be, \"SE\")\nz_valor_be &lt;- qnorm(0.975) \nlimite_inf_log_be &lt;- cl_log_be - z_valor_be * erros_padrao_log_be\nlimite_sup_log_be &lt;- cl_log_be + z_valor_be * erros_padrao_log_be\n\ntabela_escala_log10_be &lt;- data.frame(\n  Probabilidade = probabilidades_be,\n  Log10_conc = cl_log_be,\n  Limite_Inferior_95 = limite_inf_log_be,\n  Limite_Superior_95 = limite_sup_log_be\n)\n\ntabela_escala_conc_be &lt;- data.frame(\n  Probabilidade = probabilidades_be,\n  Concentracao = 10^cl_log_be,\n  Limite_Inferior_95 = 10^limite_inf_log_be,\n  Limite_Superior_95 = 10^limite_sup_log_be\n)\n\noptions(digits = 6) \n\nprint(tabela_escala_log10_be)\n\n          Probabilidade Log10_conc Limite_Inferior_95 Limite_Superior_95\np = 0.01:          0.01 -1.2111644         -2.0676481         -0.3546806\np = 0.02:          0.02 -0.7940017         -1.5096138         -0.0783896\np = 0.03:          0.03 -0.5293253         -1.1571410          0.0984903\np = 0.04:          0.04 -0.3302196         -0.8932204          0.2327811\np = 0.05:          0.05 -0.1682625         -0.6796323          0.3431072\np = 0.06:          0.06 -0.0304116         -0.4988685          0.4380453\np = 0.07:          0.07  0.0904568         -0.3413933          0.5223069\np = 0.08:          0.08  0.1986799         -0.2014262          0.5987861\np = 0.09:          0.09  0.2971046         -0.0751984          0.6694075\np = 0.10:          0.10  0.3877046          0.0398793          0.7355299\np = 0.15:          0.15  0.7628130          0.4985345          1.0270915\np = 0.20:          0.20  1.0609372          0.8279282          1.2939463\np = 0.25:          0.25  1.3167013          1.0744930          1.5589095\np = 0.30:          0.30  1.5463853          1.2697424          1.8230282\np = 0.35:          0.35  1.7592218          1.4353964          2.0830472\np = 0.40:          0.40  1.9611828          1.5840611          2.3383045\np = 0.45:          0.45  2.1565824          1.7229089          2.5902559\np = 0.50:          0.50  2.3488840          1.8564217          2.8413463\np = 0.55:          0.55  2.5411856          1.9878208          3.0945505\np = 0.60:          0.60  2.7365852          2.1198163          3.3533542\np = 0.65:          0.65  2.9385462          2.2550843          3.6220082\np = 0.70:          0.70  3.1513827          2.3967012          3.9060642\np = 0.75:          0.75  3.3810668          2.5487306          4.2134029\np = 0.80:          0.80  3.6368308          2.7172984          4.5563632\np = 0.85:          0.85  3.9349550          2.9130737          4.9568364\np = 0.90:          0.90  4.3100634          3.1586175          5.4615093\np = 0.91:          0.91  4.4006635          3.2178217          5.5835052\np = 0.92:          0.92  4.4990881          3.2821013          5.7160749\np = 0.93:          0.93  4.6073113          3.3527384          5.8618841\np = 0.94:          0.94  4.7281796          3.4315819          6.0247773\np = 0.95:          0.95  4.8660305          3.5214484          6.2106126\np = 0.96:          0.96  5.0279877          3.6269631          6.4290122\np = 0.97:          0.97  5.2270934          3.7565926          6.6975941\np = 0.98:          0.98  5.4917697          3.9287841          7.0547553\np = 0.99:          0.99  5.9089324          4.1999355          7.6179293\n\nprint(tabela_escala_conc_be)\n\n          Probabilidade Concentracao Limite_Inferior_95 Limite_Superior_95\np = 0.01:          0.01  6.14944e-02        8.55760e-03        4.41895e-01\np = 0.02:          0.02  1.60694e-01        3.09304e-02        8.34854e-01\np = 0.03:          0.03  2.95580e-01        6.96400e-02        1.25456e+00\np = 0.04:          0.04  4.67499e-01        1.27873e-01        1.70915e+00\np = 0.05:          0.05  6.78793e-01        2.09107e-01        2.20347e+00\np = 0.06:          0.06  9.32370e-01        3.17053e-01        2.74186e+00\np = 0.07:          0.07  1.23156e+00        4.55624e-01        3.32895e+00\np = 0.08:          0.08  1.58008e+00        6.28889e-01        3.96996e+00\np = 0.09:          0.09  1.98200e+00        8.41011e-01        4.67097e+00\np = 0.10:          0.10  2.44177e+00        1.09617e+00        5.43914e+00\np = 0.15:          0.15  5.79179e+00        3.15162e+00        1.06437e+01\np = 0.20:          0.20  1.15063e+01        6.72865e+00        1.96764e+01\np = 0.25:          0.25  2.07349e+01        1.18712e+01        3.62168e+01\np = 0.30:          0.30  3.51872e+01        1.86098e+01        6.65316e+01\np = 0.35:          0.35  5.74410e+01        2.72519e+01        1.21073e+02\np = 0.40:          0.40  9.14498e+01        3.83761e+01        2.17924e+02\np = 0.45:          0.45  1.43411e+02        5.28334e+01        3.89274e+02\np = 0.50:          0.50  2.23298e+02        7.18492e+01        6.93979e+02\np = 0.55:          0.55  3.47685e+02        9.72346e+01        1.24323e+03\np = 0.60:          0.60  5.45237e+02        1.31770e+02        2.25608e+03\np = 0.65:          0.65  8.68053e+02        1.79922e+02        4.18801e+03\np = 0.70:          0.70  1.41704e+03        2.49288e+02        8.05498e+03\np = 0.75:          0.75  2.40473e+03        3.53778e+02        1.63457e+04\np = 0.80:          0.80  4.33342e+03        5.21553e+02        3.60050e+04\np = 0.85:          0.85  8.60905e+03        8.18604e+02        9.05391e+04\np = 0.90:          0.90  2.04204e+04        1.44085e+03        2.89407e+05\np = 0.91:          0.91  2.51573e+04        1.65128e+03        3.83270e+05\np = 0.92:          0.92  3.15564e+04        1.91470e+03        5.20086e+05\np = 0.93:          0.93  4.04866e+04        2.25288e+03        7.27586e+05\np = 0.94:          0.94  5.34785e+04        2.70136e+03        1.05871e+06\np = 0.95:          0.95  7.34566e+04        3.32237e+03        1.62410e+06\np = 0.96:          0.96  1.06657e+05        4.23607e+03        2.68542e+06\np = 0.97:          0.97  1.68692e+05        5.70943e+03        4.98418e+06\np = 0.98:          0.98  3.10291e+05        8.48758e+03        1.13437e+07\np = 0.99:          0.99  8.10835e+05        1.58466e+04        4.14886e+07\n\nlconc_grafico_be &lt;- data.frame(lconc_be = seq(0, max(dados_be$lconc_be) + 0.1, length.out = 200))\n\npredicoes_be &lt;- predict(modelo_probit_be, newdata = lconc_grafico_be, type = \"link\", se.fit = TRUE)\n\nz_valor_be &lt;- qnorm(0.975)\nlconc_grafico_be$prob_predita_be &lt;- pnorm(predicoes_be$fit)\nlconc_grafico_be$prob_superior_be &lt;- pnorm(predicoes_be$fit + z_valor_be * predicoes_be$se.fit)\nlconc_grafico_be$prob_inferior_be &lt;- pnorm(predicoes_be$fit - z_valor_be * predicoes_be$se.fit)\n\nlc50_log_be &lt;- as.numeric(dose.p(modelo_probit_be, p = 0.50))\n\nlc50_conc_be &lt;- 10^lc50_log_be\n\nx_lim_inferior_be &lt;- -1.5 \nx_lim_superior_be &lt;- 1    \n\nlconc_grafico_be &lt;- data.frame(lconc_be = seq(x_lim_inferior_be, x_lim_superior_be, length.out = 200))\n\npredicoes_be &lt;- predict(modelo_probit_be, newdata = lconc_grafico_be, type = \"link\", se.fit = TRUE)\nz_valor_be &lt;- qnorm(0.975)\nlconc_grafico_be$prob_predita_be &lt;- pnorm(predicoes_be$fit)\nlconc_grafico_be$prob_superior_be &lt;- pnorm(predicoes_be$fit + z_valor_be * predicoes_be$se.fit)\nlconc_grafico_be$prob_inferior_be &lt;- pnorm(predicoes_be$fit - z_valor_be * predicoes_be$se.fit)\n\ngrafico_probit_final_be &lt;- ggplot() +\n  geom_ribbon(data = lconc_grafico_be,\n              aes(x = lconc_be, ymin = prob_inferior_be * 100, ymax = prob_superior_be * 100),\n              fill = \"skyblue\", alpha = 0.5) +\n  geom_line(data = lconc_grafico_be,\n            aes(x = lconc_be, y = prob_predita_be * 100),\n            color = \"blue\", size = 1) +\n  geom_point(data = dados_be,\n             aes(x = lconc_be, y = mort_prop_be * 100),\n             color = \"red\", size = 4) +\n  geom_hline(yintercept = 50, linetype = \"dashed\", color = \"black\", size = 0.7) +\n  geom_vline(xintercept = lc50_log_be, linetype = \"dashed\", color = \"black\", size = 0.7) +\n  labs(\n    title = \"Curva dose-resposta (Modelo Probit) - Benevia\",\n    x = \"Log10 (Concentração)\",\n    y = \"Mortalidade observada e prevista (%)\"\n  ) +\n  annotate(\"text\", \n           x = lc50_log_be, \n           y = 45, \n           label = paste(\"LC50 =\", format(lc50_conc_be, digits = 4)), \n           hjust = -0.1,\n           vjust = 1,\n           fontface = \"bold\",\n           color = \"black\") +\n  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 10), expand = c(0, 0)) +\n  scale_x_continuous(limits = c(x_lim_inferior_be, x_lim_superior_be), breaks = seq(-4, 1, 0.5)) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\nprint(grafico_probit_final_be)\n\n\n\n\n\n\n\n\n\n\nDelegate\n\ndados_de &lt;- data.frame(\n  conc = c(0.1, 1),      \n  total = c(60, 60),                   \n  mortos = c(0,0)     \n)\n\ndados_de$mort_prop_de &lt;- dados_de$mortos / dados_de$total \ndados_de$lconc_de &lt;- log10(dados_de$conc)             \n\nprint(\"Dados Iniciais:\")\n\n[1] \"Dados Iniciais:\"\n\nprint(dados_de)\n\n  conc total mortos mort_prop_de lconc_de\n1  0.1    60      0            0       -1\n2  1.0    60      0            0        0\n\nmodelo_reg_de &lt;- lm(mort_prop_de ~ lconc_de, data = dados_de)\n\nprint(anova(modelo_reg_de))\n\nAnalysis of Variance Table\n\nResponse: mort_prop_de\n          Df Sum Sq Mean Sq F value Pr(&gt;F)\nlconc_de   1      0       0     NaN    NaN\nResiduals  0      0     NaN               \n\nprint(summary(modelo_reg_de))\n\n\nCall:\nlm(formula = mort_prop_de ~ lconc_de, data = dados_de)\n\nResiduals:\nALL 2 residuals are 0: no residual degrees of freedom!\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)        0        NaN     NaN      NaN\nlconc_de           0        NaN     NaN      NaN\n\nResidual standard error: NaN on 0 degrees of freedom\nMultiple R-squared:   NaN,  Adjusted R-squared:   NaN \nF-statistic:  NaN on 1 and 0 DF,  p-value: NA\n\nmodelo_probit_de &lt;- glm(\n  cbind(mortos, total - mortos) ~ lconc_de,\n  data = dados_de,\n  family = binomial(link = \"probit\")\n)\n\nprint(summary(modelo_probit_de))\n\n\nCall:\nglm(formula = cbind(mortos, total - mortos) ~ lconc_de, family = binomial(link = \"probit\"), \n    data = dados_de)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept) -6.99e+00   9.44e+03       0        1\nlconc_de     1.45e-15   1.33e+04       0        1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 0.0000e+00  on 1  degrees of freedom\nResidual deviance: 3.3515e-10  on 0  degrees of freedom\nAIC: 4\n\nNumber of Fisher Scoring iterations: 22\n\npearson_chisq_de &lt;- sum(residuals(modelo_probit_de, type = \"pearson\")^2)\ndf_chisq_de &lt;- nrow(dados_de) - length(coef(modelo_probit_de))\np_valor_chisq_de &lt;- pchisq(pearson_chisq_de, df = df_chisq_de, lower.tail = FALSE)\n\ncat(paste(\"Estatística Qui-quadrado de Pearson:\", round(pearson_chisq_de, 4), \"\\n\"))\n\nEstatística Qui-quadrado de Pearson: 0 \n\ncat(paste(\"Graus de Liberdade (DF):\", df_chisq_de, \"\\n\"))\n\nGraus de Liberdade (DF): 0 \n\ncat(paste(\"Pr &gt; ChiSq (p-valor):\", round(p_valor_chisq_de, 4), \"\\n\\n\"))\n\nPr &gt; ChiSq (p-valor): 0 \n\nprobabilidades_de &lt;- c(\n  seq(from = 0.01, to = 0.10, by = 0.01),\n  seq(from = 0.15, to = 0.90, by = 0.05),\n  seq(from = 0.91, to = 0.99, by = 0.01)\n)\n\ncl_log_de &lt;- dose.p(modelo_probit_de, p = probabilidades_de)\nerros_padrao_log_de &lt;- attr(cl_log_de, \"SE\")\nz_valor_de &lt;- qnorm(0.975) \nlimite_inf_log_de &lt;- cl_log_de - z_valor_de * erros_padrao_log_de\nlimite_sup_log_de &lt;- cl_log_de + z_valor_de * erros_padrao_log_de\n\ntabela_escala_log10_de &lt;- data.frame(\n  Probabilidade = probabilidades_de,\n  Log10_conc = cl_log_de,\n  Limite_Inferior_95 = limite_inf_log_de,\n  Limite_Superior_95 = limite_sup_log_de\n)\n\ntabela_escala_conc_de &lt;- data.frame(\n  Probabilidade = probabilidades_de,\n  Concentracao = 10^cl_log_de,\n  Limite_Inferior_95 = 10^limite_inf_log_de,\n  Limite_Superior_95 = 10^limite_sup_log_de\n)\n\noptions(digits = 6) \n\nprint(tabela_escala_log10_de)\n\n          Probabilidade  Log10_conc Limite_Inferior_95 Limite_Superior_95\np = 0.01:          0.01 3.22082e+15       -5.82243e+34        5.82243e+34\np = 0.02:          0.02 3.40917e+15       -6.16293e+34        6.16293e+34\np = 0.03:          0.03 3.52868e+15       -6.37896e+34        6.37896e+34\np = 0.04:          0.04 3.61858e+15       -6.54147e+34        6.54147e+34\np = 0.05:          0.05 3.69170e+15       -6.67366e+34        6.67366e+34\np = 0.06:          0.06 3.75394e+15       -6.78618e+34        6.78618e+34\np = 0.07:          0.07 3.80851e+15       -6.88483e+34        6.88483e+34\np = 0.08:          0.08 3.85738e+15       -6.97317e+34        6.97317e+34\np = 0.09:          0.09 3.90182e+15       -7.05350e+34        7.05350e+34\np = 0.10:          0.10 3.94272e+15       -7.12745e+34        7.12745e+34\np = 0.15:          0.15 4.11209e+15       -7.43362e+34        7.43362e+34\np = 0.20:          0.20 4.24669e+15       -7.67695e+34        7.67695e+34\np = 0.25:          0.25 4.36217e+15       -7.88571e+34        7.88571e+34\np = 0.30:          0.30 4.46588e+15       -8.07318e+34        8.07318e+34\np = 0.35:          0.35 4.56198e+15       -8.24690e+34        8.24690e+34\np = 0.40:          0.40 4.65316e+15       -8.41174e+34        8.41174e+34\np = 0.45:          0.45 4.74139e+15       -8.57123e+34        8.57123e+34\np = 0.50:          0.50 4.82821e+15       -8.72819e+34        8.72819e+34\np = 0.55:          0.55 4.91504e+15       -8.88515e+34        8.88515e+34\np = 0.60:          0.60 5.00326e+15       -9.04464e+34        9.04464e+34\np = 0.65:          0.65 5.09445e+15       -9.20948e+34        9.20948e+34\np = 0.70:          0.70 5.19055e+15       -9.38320e+34        9.38320e+34\np = 0.75:          0.75 5.29425e+15       -9.57067e+34        9.57067e+34\np = 0.80:          0.80 5.40973e+15       -9.77943e+34        9.77943e+34\np = 0.85:          0.85 5.54434e+15       -1.00228e+35        1.00228e+35\np = 0.90:          0.90 5.71370e+15       -1.03289e+35        1.03289e+35\np = 0.91:          0.91 5.75461e+15       -1.04029e+35        1.04029e+35\np = 0.92:          0.92 5.79905e+15       -1.04832e+35        1.04832e+35\np = 0.93:          0.93 5.84791e+15       -1.05715e+35        1.05715e+35\np = 0.94:          0.94 5.90249e+15       -1.06702e+35        1.06702e+35\np = 0.95:          0.95 5.96473e+15       -1.07827e+35        1.07827e+35\np = 0.96:          0.96 6.03785e+15       -1.09149e+35        1.09149e+35\np = 0.97:          0.97 6.12775e+15       -1.10774e+35        1.10774e+35\np = 0.98:          0.98 6.24725e+15       -1.12935e+35        1.12935e+35\np = 0.99:          0.99 6.43561e+15       -1.16340e+35        1.16340e+35\n\nprint(tabela_escala_conc_de)\n\n          Probabilidade Concentracao Limite_Inferior_95 Limite_Superior_95\np = 0.01:          0.01          Inf                  0                Inf\np = 0.02:          0.02          Inf                  0                Inf\np = 0.03:          0.03          Inf                  0                Inf\np = 0.04:          0.04          Inf                  0                Inf\np = 0.05:          0.05          Inf                  0                Inf\np = 0.06:          0.06          Inf                  0                Inf\np = 0.07:          0.07          Inf                  0                Inf\np = 0.08:          0.08          Inf                  0                Inf\np = 0.09:          0.09          Inf                  0                Inf\np = 0.10:          0.10          Inf                  0                Inf\np = 0.15:          0.15          Inf                  0                Inf\np = 0.20:          0.20          Inf                  0                Inf\np = 0.25:          0.25          Inf                  0                Inf\np = 0.30:          0.30          Inf                  0                Inf\np = 0.35:          0.35          Inf                  0                Inf\np = 0.40:          0.40          Inf                  0                Inf\np = 0.45:          0.45          Inf                  0                Inf\np = 0.50:          0.50          Inf                  0                Inf\np = 0.55:          0.55          Inf                  0                Inf\np = 0.60:          0.60          Inf                  0                Inf\np = 0.65:          0.65          Inf                  0                Inf\np = 0.70:          0.70          Inf                  0                Inf\np = 0.75:          0.75          Inf                  0                Inf\np = 0.80:          0.80          Inf                  0                Inf\np = 0.85:          0.85          Inf                  0                Inf\np = 0.90:          0.90          Inf                  0                Inf\np = 0.91:          0.91          Inf                  0                Inf\np = 0.92:          0.92          Inf                  0                Inf\np = 0.93:          0.93          Inf                  0                Inf\np = 0.94:          0.94          Inf                  0                Inf\np = 0.95:          0.95          Inf                  0                Inf\np = 0.96:          0.96          Inf                  0                Inf\np = 0.97:          0.97          Inf                  0                Inf\np = 0.98:          0.98          Inf                  0                Inf\np = 0.99:          0.99          Inf                  0                Inf\n\nlconc_grafico_de &lt;- data.frame(lconc_de = seq(0, max(dados_de$lconc_de) + 0.1, length.out = 200))\n\npredicoes_de &lt;- predict(modelo_probit_de, newdata = lconc_grafico_de, type = \"link\", se.fit = TRUE)\n\nz_valor_de &lt;- qnorm(0.975)\nlconc_grafico_de$prob_predita_de &lt;- pnorm(predicoes_de$fit)\nlconc_grafico_de$prob_superior_de &lt;- pnorm(predicoes_de$fit + z_valor_de * predicoes_de$se.fit)\nlconc_grafico_de$prob_inferior_de &lt;- pnorm(predicoes_de$fit - z_valor_de * predicoes_de$se.fit)\n\nlc50_log_de &lt;- as.numeric(dose.p(modelo_probit_de, p = 0.50))\n\nlc50_conc_de &lt;- 10^lc50_log_de\n\nx_lim_inferior_de &lt;- -1.5 \nx_lim_superior_de &lt;- 1    \n\nlconc_grafico_de &lt;- data.frame(lconc_de = seq(x_lim_inferior_de, x_lim_superior_de, length.out = 200))\n\npredicoes_de &lt;- predict(modelo_probit_de, newdata = lconc_grafico_de, type = \"link\", se.fit = TRUE)\nz_valor_de &lt;- qnorm(0.975)\nlconc_grafico_de$prob_predita_de &lt;- pnorm(predicoes_de$fit)\nlconc_grafico_de$prob_superior_de &lt;- pnorm(predicoes_de$fit + z_valor_de * predicoes_de$se.fit)\nlconc_grafico_de$prob_inferior_de &lt;- pnorm(predicoes_de$fit - z_valor_de * predicoes_de$se.fit)\n\ngrafico_probit_final_de &lt;- ggplot() +\n  geom_ribbon(data = lconc_grafico_de,\n              aes(x = lconc_de, ymin = prob_inferior_de * 100, ymax = prob_superior_de * 100),\n              fill = \"skyblue\", alpha = 0.5) +\n  geom_line(data = lconc_grafico_de,\n            aes(x = lconc_de, y = prob_predita_de * 100),\n            color = \"blue\", size = 1) +\n  geom_point(data = dados_de,\n             aes(x = lconc_de, y = mort_prop_de * 100),\n             color = \"red\", size = 4) +\n  geom_hline(yintercept = 50, linetype = \"dashed\", color = \"black\", size = 0.7) +\n  geom_vline(xintercept = lc50_log_de, linetype = \"dashed\", color = \"black\", size = 0.7) +\n  labs(\n    title = \"Curva dose-resposta (Modelo Probit) - Delegate\",\n    x = \"Log10 (Concentração)\",\n    y = \"Mortalidade observada e prevista (%)\"\n  ) +\n  annotate(\"text\", \n           x = lc50_log_de, \n           y = 45, \n           label = paste(\"LC50 =\", format(lc50_conc_de, digits = 4)), \n           hjust = -0.1,\n           vjust = 1,\n           fontface = \"bold\",\n           color = \"black\") +\n  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 10), expand = c(0, 0)) +\n  scale_x_continuous(limits = c(x_lim_inferior_de, x_lim_superior_de), breaks = seq(-4, 1, 0.5)) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\nprint(grafico_probit_final_de)\n\n\n\n\n\n\n\n\n\n\nJoiner\n\ndados_jo &lt;- data.frame(\n  conc = c(0.00375, 0.0075, 0.01, 0.015, 0.03, 0.07, 0.1, 1, 3, 5, 10),      \n  total = c(60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60),                   \n  mortos = c(43, 6, 14, 2, 12, 15, 26, 36, 45, 49, 46)     \n)\n\ndados_jo$mort_prop_jo &lt;- dados_jo$mortos / dados_jo$total \ndados_jo$lconc_jo &lt;- log10(dados_jo$conc)             \n\nprint(\"Dados Iniciais:\")\n\n[1] \"Dados Iniciais:\"\n\nprint(dados_jo)\n\n       conc total mortos mort_prop_jo  lconc_jo\n1   0.00375    60     43    0.7166667 -2.425969\n2   0.00750    60      6    0.1000000 -2.124939\n3   0.01000    60     14    0.2333333 -2.000000\n4   0.01500    60      2    0.0333333 -1.823909\n5   0.03000    60     12    0.2000000 -1.522879\n6   0.07000    60     15    0.2500000 -1.154902\n7   0.10000    60     26    0.4333333 -1.000000\n8   1.00000    60     36    0.6000000  0.000000\n9   3.00000    60     45    0.7500000  0.477121\n10  5.00000    60     49    0.8166667  0.698970\n11 10.00000    60     46    0.7666667  1.000000\n\nmodelo_reg_jo &lt;- lm(mort_prop_jo ~ lconc_jo, data = dados_jo)\n\nprint(anova(modelo_reg_jo))\n\nAnalysis of Variance Table\n\nResponse: mort_prop_jo\n          Df Sum Sq Mean Sq F value Pr(&gt;F)  \nlconc_jo   1 0.4404  0.4404   9.357 0.0136 *\nResiduals  9 0.4236  0.0471                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nprint(summary(modelo_reg_jo))\n\n\nCall:\nlm(formula = mort_prop_jo ~ lconc_jo, data = dados_jo)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.2546 -0.1380 -0.0015  0.0380  0.5311 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.5981     0.0823    7.27  4.7e-05 ***\nlconc_jo      0.1701     0.0556    3.06    0.014 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.217 on 9 degrees of freedom\nMultiple R-squared:  0.51,  Adjusted R-squared:  0.455 \nF-statistic: 9.36 on 1 and 9 DF,  p-value: 0.0136\n\nmodelo_probit_jo &lt;- glm(\n  cbind(mortos, total - mortos) ~ lconc_jo,\n  data = dados_jo,\n  family = binomial(link = \"probit\")\n)\n\nprint(summary(modelo_probit_jo))\n\n\nCall:\nglm(formula = cbind(mortos, total - mortos) ~ lconc_jo, family = binomial(link = \"probit\"), \n    data = dados_jo)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.2635     0.0647    4.07  4.7e-05 ***\nlconc_jo      0.4501     0.0447   10.06  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 233.58  on 10  degrees of freedom\nResidual deviance: 124.18  on  9  degrees of freedom\nAIC: 172.9\n\nNumber of Fisher Scoring iterations: 4\n\npearson_chisq_jo &lt;- sum(residuals(modelo_probit_jo, type = \"pearson\")^2)\ndf_chisq_jo &lt;- nrow(dados_jo) - length(coef(modelo_probit_jo))\np_valor_chisq_jo &lt;- pchisq(pearson_chisq_jo, df = df_chisq_jo, lower.tail = FALSE)\n\ncat(paste(\"Estatística Qui-quadrado de Pearson:\", round(pearson_chisq_jo, 4), \"\\n\"))\n\nEstatística Qui-quadrado de Pearson: 138.0422 \n\ncat(paste(\"Graus de Liberdade (DF):\", df_chisq_jo, \"\\n\"))\n\nGraus de Liberdade (DF): 9 \n\ncat(paste(\"Pr &gt; ChiSq (p-valor):\", round(p_valor_chisq_jo, 4), \"\\n\\n\"))\n\nPr &gt; ChiSq (p-valor): 0 \n\nprobabilidades_jo &lt;- c(\n  seq(from = 0.01, to = 0.10, by = 0.01),\n  seq(from = 0.15, to = 0.90, by = 0.05),\n  seq(from = 0.91, to = 0.99, by = 0.01)\n)\n\ncl_log_jo &lt;- dose.p(modelo_probit_jo, p = probabilidades_jo)\nerros_padrao_log_jo &lt;- attr(cl_log_jo, \"SE\")\nz_valor_jo &lt;- qnorm(0.975) \nlimite_inf_log_jo &lt;- cl_log_jo - z_valor_jo * erros_padrao_log_jo\nlimite_sup_log_jo &lt;- cl_log_jo + z_valor_jo * erros_padrao_log_jo\n\ntabela_escala_log10_jo &lt;- data.frame(\n  Probabilidade = probabilidades_jo,\n  Log10_conc = cl_log_jo,\n  Limite_Inferior_95 = limite_inf_log_jo,\n  Limite_Superior_95 = limite_sup_log_jo\n)\n\ntabela_escala_conc_jo &lt;- data.frame(\n  Probabilidade = probabilidades_jo,\n  Concentracao = 10^cl_log_jo,\n  Limite_Inferior_95 = 10^limite_inf_log_jo,\n  Limite_Superior_95 = 10^limite_sup_log_jo\n)\n\noptions(digits = 6) \n\nprint(tabela_escala_log10_jo)\n\n          Probabilidade Log10_conc Limite_Inferior_95 Limite_Superior_95\np = 0.01:          0.01  -5.753995         -6.7297193         -4.7782698\np = 0.02:          0.02  -5.148341         -6.0096998         -4.2869818\np = 0.03:          0.03  -4.764073         -5.5534174         -3.9747285\np = 0.04:          0.04  -4.475003         -5.2105449         -3.7394615\np = 0.05:          0.05  -4.239867         -4.9319371         -3.5477974\np = 0.06:          0.06  -4.039730         -4.6950470         -3.3844122\np = 0.07:          0.07  -3.864248         -4.4875630         -3.2409331\np = 0.08:          0.08  -3.707125         -4.3019909         -3.1122596\np = 0.09:          0.09  -3.564228         -4.1334141         -2.9950426\np = 0.10:          0.10  -3.432692         -3.9784252         -2.8869579\np = 0.15:          0.15  -2.888094         -3.3392408         -2.4369471\np = 0.20:          0.20  -2.455265         -2.8355782         -2.0749519\np = 0.25:          0.25  -2.083936         -2.4086452         -1.7592275\np = 0.30:          0.30  -1.750472         -2.0317978         -1.4691457\np = 0.35:          0.35  -1.441467         -1.6910879         -1.1918463\np = 0.40:          0.40  -1.148252         -1.3785425         -0.9179613\np = 0.45:          0.45  -0.864563         -1.0887619         -0.6403636\np = 0.50:          0.50  -0.585371         -0.8166736         -0.3540693\np = 0.55:          0.55  -0.306180         -0.5564770         -0.0558833\np = 0.60:          0.60  -0.022491         -0.3017753          0.2567933\np = 0.65:          0.65   0.270724         -0.0459488          0.5873971\np = 0.70:          0.70   0.579729          0.2180368          0.9414209\np = 0.75:          0.75   0.913193          0.4985814          1.3278055\np = 0.80:          0.80   1.284522          0.8074736          1.7615706\np = 0.85:          0.85   1.717351          1.1644782          2.2702238\np = 0.90:          0.90   2.261949          1.6107074          2.9131898\np = 0.91:          0.91   2.393485          1.7181363          3.0688346\np = 0.92:          0.92   2.536382          1.8347220          3.2380427\np = 0.93:          0.93   2.693505          1.9627845          3.4242258\np = 0.94:          0.94   2.868987          2.1056680          3.6323053\np = 0.95:          0.95   3.069124          2.2684671          3.8697815\np = 0.96:          0.96   3.304260          2.4595460          4.1489745\np = 0.97:          0.97   3.593330          2.6942157          4.4924443\np = 0.98:          0.98   3.977598          3.0058340          4.9493618\np = 0.99:          0.99   4.583252          3.4963811          5.6701222\n\nprint(tabela_escala_conc_jo)\n\n          Probabilidade Concentracao Limite_Inferior_95 Limite_Superior_95\np = 0.01:          0.01  1.76200e-06        1.86329e-07        1.66621e-05\np = 0.02:          0.02  7.10656e-06        9.77913e-07        5.16438e-05\np = 0.03:          0.03  1.72158e-05        2.79629e-06        1.05992e-04\np = 0.04:          0.04  3.34963e-05        6.15822e-06        1.82196e-04\np = 0.05:          0.05  5.75616e-05        1.16967e-05        2.83271e-04\np = 0.06:          0.06  9.12579e-05        2.01815e-05        4.12656e-04\np = 0.07:          0.07  1.36695e-04        3.25415e-05        5.74205e-04\np = 0.08:          0.08  1.96279e-04        4.98895e-05        7.72219e-04\np = 0.09:          0.09  2.72754e-04        7.35505e-05        1.01148e-03\np = 0.10:          0.10  3.69240e-04        1.05093e-04        1.29730e-03\np = 0.15:          0.15  1.29392e-03        4.57888e-04        3.65639e-03\np = 0.20:          0.20  3.50538e-03        1.46023e-03        8.41488e-03\np = 0.25:          0.25  8.24259e-03        3.90261e-03        1.74089e-02\np = 0.30:          0.30  1.77635e-02        9.29399e-03        3.39511e-02\np = 0.35:          0.35  3.61854e-02        2.03663e-02        6.42915e-02\np = 0.40:          0.40  7.10801e-02        4.18271e-02        1.20792e-01\np = 0.45:          0.45  1.36596e-01        8.15151e-02        2.28895e-01\np = 0.50:          0.50  2.59794e-01        1.52520e-01        4.42518e-01\np = 0.55:          0.55  4.94106e-01        2.77666e-01        8.79259e-01\np = 0.60:          0.60  9.49531e-01        4.99143e-01        1.80631e+00\np = 0.65:          0.65  1.86519e+00        8.99604e-01        3.86720e+00\np = 0.70:          0.70  3.79952e+00        1.65210e+00        8.73818e+00\np = 0.75:          0.75  8.18829e+00        3.15197e+00        2.12719e+01\np = 0.80:          0.80  1.92541e+01        6.41909e+00        5.77525e+01\np = 0.85:          0.85  5.21616e+01        1.46042e+01        1.86305e+02\np = 0.90:          0.90  1.82788e+02        4.08044e+01        8.18823e+02\np = 0.91:          0.91  2.47449e+02        5.22560e+01        1.17175e+03\np = 0.92:          0.92  3.43861e+02        6.83474e+01        1.72999e+03\np = 0.93:          0.93  4.93748e+02        9.17877e+01        2.65599e+03\np = 0.94:          0.94  7.39583e+02        1.27546e+02        4.28850e+03\np = 0.95:          0.95  1.17253e+03        1.85553e+02        7.40937e+03\np = 0.96:          0.96  2.01493e+03        2.88102e+02        1.40921e+04\np = 0.97:          0.97  3.92040e+03        4.94556e+02        3.10774e+04\np = 0.98:          0.98  9.49725e+03        1.01352e+03        8.89942e+04\np = 0.99:          0.99  3.83047e+04        3.13604e+03        4.67867e+05\n\nlconc_grafico_jo &lt;- data.frame(lconc_jo = seq(0, max(dados_jo$lconc_jo) + 0.1, length.out = 200))\n\npredicoes_jo &lt;- predict(modelo_probit_jo, newdata = lconc_grafico_jo, type = \"link\", se.fit = TRUE)\n\nz_valor_jo &lt;- qnorm(0.975)\nlconc_grafico_jo$prob_predita_jo &lt;- pnorm(predicoes_jo$fit)\nlconc_grafico_jo$prob_superior_jo &lt;- pnorm(predicoes_jo$fit + z_valor_jo * predicoes_jo$se.fit)\nlconc_grafico_jo$prob_inferior_jo &lt;- pnorm(predicoes_jo$fit - z_valor_jo * predicoes_jo$se.fit)\n\nlc50_log_jo &lt;- as.numeric(dose.p(modelo_probit_jo, p = 0.50))\n\nlc50_conc_jo &lt;- 10^lc50_log_jo\n\nx_lim_inferior_jo &lt;- -1.5 \nx_lim_superior_jo &lt;- 1    \n\nlconc_grafico_jo &lt;- data.frame(lconc_jo = seq(x_lim_inferior_jo, x_lim_superior_jo, length.out = 200))\n\npredicoes_jo &lt;- predict(modelo_probit_jo, newdata = lconc_grafico_jo, type = \"link\", se.fit = TRUE)\nz_valor_jo &lt;- qnorm(0.975)\nlconc_grafico_jo$prob_predita_jo &lt;- pnorm(predicoes_jo$fit)\nlconc_grafico_jo$prob_superior_jo &lt;- pnorm(predicoes_jo$fit + z_valor_jo * predicoes_jo$se.fit)\nlconc_grafico_jo$prob_inferior_jo &lt;- pnorm(predicoes_jo$fit - z_valor_jo * predicoes_jo$se.fit)\n\ngrafico_probit_final_jo &lt;- ggplot() +\n  geom_ribbon(data = lconc_grafico_jo,\n              aes(x = lconc_jo, ymin = prob_inferior_jo * 100, ymax = prob_superior_jo * 100),\n              fill = \"skyblue\", alpha = 0.5) +\n  geom_line(data = lconc_grafico_jo,\n            aes(x = lconc_jo, y = prob_predita_jo * 100),\n            color = \"blue\", size = 1) +\n  geom_point(data = dados_jo,\n             aes(x = lconc_jo, y = mort_prop_jo * 100),\n             color = \"red\", size = 4) +\n  geom_hline(yintercept = 50, linetype = \"dashed\", color = \"black\", size = 0.7) +\n  geom_vline(xintercept = lc50_log_jo, linetype = \"dashed\", color = \"black\", size = 0.7) +\n  labs(\n    title = \"Curva dose-resposta (Modelo Probit) - Joiner\",\n    x = \"Log10 (Concentração)\",\n    y = \"Mortalidade observada e prevista (%)\"\n  ) +\n  annotate(\"text\", \n           x = lc50_log_jo, \n           y = 45, \n           label = paste(\"LC50 =\", format(lc50_conc_jo, digits = 4)), \n           hjust = -0.1,\n           vjust = 1,\n           fontface = \"bold\",\n           color = \"black\") +\n  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 10), expand = c(0, 0)) +\n  scale_x_continuous(limits = c(x_lim_inferior_jo, x_lim_superior_jo), breaks = seq(-4, 1, 0.5)) +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\nprint(grafico_probit_final_jo)\n\n\n\n\n\n\n\n\nInterpretação da curva dose-resposta: a CL50 corresponde no gráfico do ponto de interseção entre a linha horizontal de referência a 50% da mortalidade dos insetos, e a curva gerada pelo modelo. Foi possível estimar a CL50 apenas para o joiner (CL50 = 0.2598). Isso se deve ao fato de possuir poucos pontos para a estimação do parâmetro."
  },
  {
    "objectID": "home.html",
    "href": "home.html",
    "title": "Traça do tomateiro (Phthorimaea absoluta)",
    "section": "",
    "text": "A traça do tomateiro (Phithorimaes absoluta) (Meyrick) (Lepidoptera: Gelechiidae) é uma praga considerada chave nas culturas de tomate no mundo, ameaçando a produção do tomate em toda durante todo o cultivo. Seu ataque pode causar perdas de até 100% . Essa praga tem sua origem na América do Sul, onde teve importância limitada nessa região até 2006. Desde então, P. absoluta se espalhou por diversas regiões do mundo e hoje pode ser encontrada na América do Sul, Europa, África, Oriente Médio e Ásia Central. A praga apresenta ciclo de vida completo, com ovo, larva, pupa e adulto. A fase da vida do inseto que é praga, é a fase de lagartas, onde elas fazem minas nas folhas, reduzindo a capacidade fotossintética. Além disso, esse inseto reduz o crescimento das plantas devido suas larvas broquearem o ápice dos ramos. Além disso, suas larvas causam o abortamento de flores e broqueiam os frutos. O seu controle é feito principalmente pela aplicação de inseticidas.\n\n\n\nOvos: Pequenos, ovalados, geralmente localizadas na parte inferior das folhas.\n\n\n\n\n\n\n\nLarva: Fase que causa dano, de coloração variada (creme a esverdeada/rosada), com cabeça escura. É nessa fase que a praga confecciona minas alargadas nas folhas.\n\n\n\n\n\n\n\nPupa: Possui formato cilíndrico. Seu tamanho mede cerca de 4 mm de largura por 10 mm de comprimento. A coloração é inicialmente esverdeada, mas à medida que se desenvolve e se aproxima da emergência do adulto, sua cor muda para marrom-claro ou acastanhado, tornando-se marrom-escuro pouco antes da eclosão da mariposa.\n\n\n\n\n\n\n\nAdultos: Mariposa pequenas, com coloração acinzentada e de hábitos noturnos."
  },
  {
    "objectID": "home.html#morfologia-e-identificação",
    "href": "home.html#morfologia-e-identificação",
    "title": "Traça do tomateiro (Phthorimaea absoluta)",
    "section": "",
    "text": "Ovos: Pequenos, ovalados, geralmente localizadas na parte inferior das folhas.\n\n\n\n\n\n\n\nLarva: Fase que causa dano, de coloração variada (creme a esverdeada/rosada), com cabeça escura. É nessa fase que a praga confecciona minas alargadas nas folhas.\n\n\n\n\n\n\n\nPupa: Possui formato cilíndrico. Seu tamanho mede cerca de 4 mm de largura por 10 mm de comprimento. A coloração é inicialmente esverdeada, mas à medida que se desenvolve e se aproxima da emergência do adulto, sua cor muda para marrom-claro ou acastanhado, tornando-se marrom-escuro pouco antes da eclosão da mariposa.\n\n\n\n\n\n\n\nAdultos: Mariposa pequenas, com coloração acinzentada e de hábitos noturnos."
  }
]